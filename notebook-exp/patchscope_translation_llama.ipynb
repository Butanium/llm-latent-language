{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "\n",
    "# Fix logger bug\n",
    "import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "\n",
    "th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model = \"croissantllm/CroissantLLMBase\"\n",
    "model_path = None\n",
    "check_translation_performance = False\n",
    "batch_size = 64\n",
    "thinking_langs = [\"en\", \"fr\"]\n",
    "langs = [\"en\", \"fr\", \"de\", \"ru\", \"zh\"]\n",
    "method = \"logit_lens\"\n",
    "device = \"auto\"\n",
    "trust_remote_code = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "del method  # Not used in this notebook\n",
    "langs = np.array(langs)\n",
    "out_langs = {lang: np.array([l for l in langs if l != lang]) for lang in langs}\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    dispatch=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import run_prompts, TargetPromptBatch, patchscope_lens\n",
    "from translation_tools import translation_prompts\n",
    "\n",
    "from translation_tools import get_bn_dataset as get_translations\n",
    "from random import sample\n",
    "\n",
    "# from translation_tools import get_gpt4_dataset as get_translations\n",
    "from utils import plot_ci, ulist, plot_k, plot_topk_tokens\n",
    "\n",
    "\n",
    "def cross_translation_plot(\n",
    "    source_input_lang,\n",
    "    source_target_lang,\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    extra_langs=None,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    ax=None,\n",
    "    time_=None,\n",
    "    k=4,\n",
    "    min_pairs = 30,\n",
    "):\n",
    "    \"\"\"\n",
    "    Patchscope with source hidden from:\n",
    "    index -1 and Prompt = source_input_lang: A -> source_target_lang:\n",
    "    Into target prompt:\n",
    "    into index = -1, prompt = input_lang: A -> target_lang:\n",
    "    Then plot with latent_langs, target_lang, source_target_lang\n",
    "    \"\"\"\n",
    "    if extra_langs is None:\n",
    "        extra_langs = []\n",
    "    if isinstance(extra_langs, str):\n",
    "        extra_langs = [extra_langs]\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    global source_df, target_df, target_prompts, target_probs, latent_probs, source_prompts\n",
    "    if time_ is None:\n",
    "        time_ = str(int(time()))\n",
    "    else:\n",
    "        time_ = str(time_)\n",
    "    if isinstance(extra_langs, str):\n",
    "        extra_langs = [extra_langs]\n",
    "    source_df = get_translations(\n",
    "        source_input_lang,\n",
    "        [source_target_lang, input_lang, target_lang, *extra_langs],\n",
    "    )\n",
    "    target_df = get_translations(\n",
    "        input_lang,\n",
    "        [source_target_lang, source_input_lang, target_lang, *extra_langs],\n",
    "    )\n",
    "    # Keep rows which word_original is in both dataframes\n",
    "    merge = pd.merge(\n",
    "        source_df.reset_index(),\n",
    "        target_df.reset_index(),\n",
    "        on=\"word_original\",\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_source\", \"_target\"),\n",
    "    )\n",
    "    if num_words is not None:\n",
    "        merge = merge.sample(num_words)\n",
    "    source_df = source_df.iloc[merge[\"index_source\"]]\n",
    "    target_df = target_df.iloc[merge[\"index_target\"]]\n",
    "    extra_langs = ulist(\n",
    "        [\n",
    "            source_input_lang,\n",
    "            source_target_lang,\n",
    "            *extra_langs,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    _source_prompts = translation_prompts(\n",
    "        source_df,\n",
    "        nn_model.tokenizer,\n",
    "        source_input_lang,\n",
    "        source_target_lang,\n",
    "        [],\n",
    "        augment_tokens=False,\n",
    "    )\n",
    "    _target_prompts = translation_prompts(\n",
    "        target_df,\n",
    "        nn_model.tokenizer,\n",
    "        input_lang,\n",
    "        target_lang,\n",
    "        [l for l in extra_langs if l != target_lang],\n",
    "        augment_tokens=False,\n",
    "    )\n",
    "    collected_pairs = 0\n",
    "    source_prompts = []\n",
    "    target_prompts = []\n",
    "    for sp, tp in zip(_source_prompts, _target_prompts):\n",
    "        if tp.has_no_collisions():\n",
    "            source_prompts.append(sp)\n",
    "            target_prompts.append(tp)\n",
    "            collected_pairs += 1\n",
    "    if collected_pairs < min_pairs:\n",
    "        print(f\"Could only collect {collected_pairs} pairs for {source_input_lang} -> {source_target_lang} - {input_lang} -> {target_lang}, skipping...\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"Kept {len(source_prompts)} pairs\")\n",
    "    source_prompts_str = [p.prompt for p in source_prompts]\n",
    "\n",
    "    def transverse_patchscope(nn_model, prompt_batch, scan):\n",
    "        offset = transverse_patchscope.offset\n",
    "        target_pathscope_prompts = TargetPromptBatch.from_prompts(prompt_batch, -1)\n",
    "        source_prompt_batch = source_prompts_str[offset : offset + len(prompt_batch)]\n",
    "        transverse_patchscope.offset += len(prompt_batch)\n",
    "        return patchscope_lens(\n",
    "            nn_model, source_prompt_batch, target_pathscope_prompts, scan=scan\n",
    "        )\n",
    "\n",
    "    transverse_patchscope.offset = 0\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, get_probs=transverse_patchscope\n",
    "    )\n",
    "\n",
    "    # Get the baseline to normalize the plots\n",
    "    source_prompts_probs, _ = run_prompts(\n",
    "        nn_model, source_prompts, batch_size=batch_size, get_probs=\"next_token_probs\"\n",
    "    )\n",
    "    source_prompts_baseline = source_prompts_probs.mean()\n",
    "    target_prompts_probs, _ = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, get_probs=\"next_token_probs\"\n",
    "    )\n",
    "    target_prompts_baseline = target_prompts_probs.mean()\n",
    "\n",
    "    json_dic = {\n",
    "        target_lang: target_probs.tolist(),\n",
    "        \"source prompt probs\": source_prompts_probs.squeeze().tolist(),\n",
    "        \"target prompt probs\": target_prompts_probs.squeeze().tolist(),\n",
    "    }\n",
    "    for label, probs in latent_probs.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    path = (\n",
    "        Path(\"results\")\n",
    "        / model_name\n",
    "        / \"cross_translation\"\n",
    "        / (\n",
    "            f\"{source_input_lang}_{source_target_lang}-{input_lang}_{target_lang}-\"\n",
    "            + \"_\".join(extra_langs[2:])\n",
    "        )\n",
    "    )\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (time_ + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    colors = sns.color_palette(\"tab10\", 1 + len(extra_langs))\n",
    "    plot_ci(\n",
    "        ax1, target_probs / target_prompts_baseline, label=target_lang, color=colors[0]\n",
    "    )\n",
    "    for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "        baseline = 1\n",
    "        if label == source_target_lang:\n",
    "            baseline = source_prompts_baseline\n",
    "        else:\n",
    "            if label == source_input_lang:\n",
    "                baseline = source_prompts_baseline\n",
    "            if label == input_lang:\n",
    "                baseline = min(baseline, target_prompts_baseline)\n",
    "        plot_ci(ax1, probs / baseline, label=label, color=colors[i + 1], init=False)\n",
    "    ax1.legend()\n",
    "    title = f\"{model_name}: Patchscope from ({source_input_lang} -> {source_target_lang}) into ({input_lang} -> {target_lang})\"\n",
    "    ax1.set_title(title)\n",
    "    # Raw probabilities plot\n",
    "    plot_ci(ax2, target_probs, label=target_lang, color=colors[0])\n",
    "    for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "        plot_ci(ax2, probs, label=label, color=colors[i + 1], init=False)\n",
    "    ax2.legend()\n",
    "    ax2.set_title(title + \" - Raw probabilities\")\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (time_ + \".png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot k examples\n",
    "    fig, axes = plt.subplots(1, k, figsize=(5 * k, 5))\n",
    "    idx = th.randperm(len(source_prompts_str))[:k]\n",
    "    plot_k(\n",
    "        axes,\n",
    "        target_probs[idx],\n",
    "        label=target_lang,\n",
    "        color=colors[0],\n",
    "        k=k,\n",
    "    )\n",
    "    for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "        plot_k(\n",
    "            axes,\n",
    "            probs[idx],\n",
    "            label=label,\n",
    "            color=colors[i + 1],\n",
    "            init=False,\n",
    "            k=k,\n",
    "        )\n",
    "    axes[-1].legend()\n",
    "    fig.suptitle(title + \" - Raw probabilities\")\n",
    "    plt_file = path / (time_ + \"_k.png\")\n",
    "    fig.savefig(plt_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "    json_meta = {}\n",
    "    for i in idx:\n",
    "        json_meta[i.item()] = {\n",
    "            \"source input lang\": source_input_lang,\n",
    "            \"source target lang\": source_target_lang,\n",
    "            \"input lang\": input_lang,\n",
    "            \"target lang\": target_lang,\n",
    "            \"source prompt\": source_prompts_str[i],\n",
    "            \"source prompt target\": source_prompts[i].target_strings,\n",
    "            \"target prompt\": target_prompts[i].prompt,\n",
    "            \"target prompt target\": target_prompts[i].target_strings,\n",
    "            \"target prompt latent\": target_prompts[i].latent_strings,\n",
    "        }\n",
    "    json_df = pd.DataFrame(json_meta)\n",
    "    with pd.option_context(\n",
    "        \"display.max_colwidth\",\n",
    "        None,\n",
    "        \"display.max_columns\",\n",
    "        None,\n",
    "        \"display.max_rows\",\n",
    "        None,\n",
    "    ):\n",
    "        display(json_df)\n",
    "    target_prompt_batch = TargetPromptBatch.from_prompts(\n",
    "        [target_prompts[i].prompt for i in idx], -1\n",
    "    )\n",
    "    probs = patchscope_lens(\n",
    "        nn_model, [source_prompts_str[i] for i in idx], target_prompt_batch\n",
    "    )\n",
    "    file = path / (time_ + \"_heatmap.png\")\n",
    "    plot_topk_tokens(probs, nn_model, title=title, file=file)\n",
    "\n",
    "    meta_file = path / (time_ + \"_heatmap.meta.json\")\n",
    "    with open(meta_file, \"w\") as f:\n",
    "        json.dump(json_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coolname import generate_slug\n",
    "time_ = str(int(time())) + generate_slug(2) \n",
    "print(f\"Experiment time id: {time_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinking_langs = []\n",
    "paper_args = [\n",
    "    ('zh', 'fr', 'de', 'zh'),\n",
    "    ('zh', 'de', 'fr', 'zh'),\n",
    "    (\"fr\", \"zh\", \"en\", \"de\"),\n",
    "    ('zh', 'en', 'fr', 'zh'),\n",
    "    (\"fr\", \"zh\", \"ru\", \"en\"),\n",
    "    (\"fr\", \"zh\", \"zh\", \"en\"),\n",
    "    (\"de\", \"en\", \"de\", \"zh\"),\n",
    "    (\"de\", \"en\", \"fr\", \"zh\")\n",
    "]\n",
    "for args in paper_args:\n",
    "   cross_translation_plot(*args, time_=time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_input_lang in langs:\n",
    "    for source_target_lang in out_langs[source_input_lang]:\n",
    "        for in_lang in langs:\n",
    "            for out_lang in out_langs[in_lang]:\n",
    "                if source_input_lang == in_lang and source_target_lang == out_lang:\n",
    "                    continue\n",
    "                cross_translation_plot(\n",
    "                    source_input_lang,\n",
    "                    source_target_lang,\n",
    "                    in_lang,\n",
    "                    out_lang,\n",
    "                    thinking_langs,\n",
    "                    time_=time_,\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
