{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "from random import shuffle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Fix logger bug\n",
    "import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"lang_patchscope\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "langs = [\"fr\", \"de\", \"ru\", \"en\", \"zh\"]\n",
    "batch_size = 8\n",
    "model = \"Llama-2-7b\"\n",
    "device = \"auto\"\n",
    "# model_path = \"/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "extra_args = []\n",
    "exp_id = None\n",
    "paper_only = False\n",
    "prob_treshold = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CL Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--use-obj\", \"-o\", action=\"store_true\")\n",
    "args = parser.parse_args(extra_args)\n",
    "use_obj = args.use_obj\n",
    "print(f\"args: {args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "\n",
    "model_name = model.split(\"/\")[-1]\n",
    "langs = np.array(langs)\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    # dispatch=True,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import (\n",
    "    run_prompts,\n",
    ")\n",
    "from interventions import patchscope_lens, TargetPromptBatch\n",
    "from prompt_tools import lang_few_shot_prompts, translation_prompts\n",
    "from translation_tools import get_cloze_dataset, get_bn_dataset\n",
    "\n",
    "from display_utils import plot_topk_tokens, k_subplots, plot_results, plot_k_results\n",
    "from utils import ulist\n",
    "\n",
    "\n",
    "def plt_lang_patch(\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    few_shot_langs,\n",
    "    extra_langs=None,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    exp_id=None,\n",
    "    num_examples=9,\n",
    "    use_obj=use_obj,\n",
    "):\n",
    "    \"\"\"\n",
    "    func docstring\n",
    "    \"\"\"\n",
    "    if extra_langs is None:\n",
    "        extra_langs = []\n",
    "    if isinstance(extra_langs, str):\n",
    "        extra_langs = [extra_langs]\n",
    "    global target_prompts, target_probs, latent_probs, source_prompts\n",
    "    df_tr = get_bn_dataset(input_lang, target_lang, num_words=num_words)\n",
    "    source_prompts = translation_prompts(\n",
    "        df_tr, tokenizer, input_lang, target_lang, cut_at_obj=use_obj\n",
    "    )\n",
    "    source_prompts = [p.prompt for p in source_prompts]\n",
    "    df = get_cloze_dataset(\n",
    "        ulist([input_lang, target_lang, *extra_langs, *few_shot_langs]),\n",
    "        num_words=num_words,\n",
    "    )\n",
    "    target_prompts = lang_few_shot_prompts(\n",
    "        df,\n",
    "        tokenizer,\n",
    "        few_shot_langs,\n",
    "        target_lang,\n",
    "        [input_lang, *extra_langs],\n",
    "        num_prompts=len(source_prompts),\n",
    "    )\n",
    "\n",
    "    def lang_patchscope(nn_model, prompt_batch, scan):\n",
    "        src_prompts = source_prompts[\n",
    "            lang_patchscope.idx : lang_patchscope.idx + len(prompt_batch)\n",
    "        ]\n",
    "        lang_patchscope.idx += len(prompt_batch)\n",
    "        tgt_prompts = TargetPromptBatch.from_prompts(prompt_batch, -2)\n",
    "        return patchscope_lens(nn_model, src_prompts, tgt_prompts, scan=scan)\n",
    "\n",
    "    lang_patchscope.idx = 0\n",
    "\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, get_probs=lang_patchscope\n",
    "    )\n",
    "\n",
    "    json_dic = {\n",
    "        target_lang: target_probs.tolist(),\n",
    "    }\n",
    "    for label, probs in latent_probs.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    pref = \"_\".join([])\n",
    "    path = (\n",
    "        Path(\"results\")\n",
    "        / model_name\n",
    "        / exp_name\n",
    "        / (f\"{pref}-{input_lang}_{target_lang}-\")\n",
    "    )\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (exp_id + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "    # fig, (ax, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    pref = pref.replace(\"_\", \" \")\n",
    "    title = f\"{model_name}: {exp_name} from ({input_lang} -> {target_lang})\"\n",
    "    plot_results(ax, target_probs, latent_probs, target_lang)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (exp_id + \".png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot k examples\n",
    "    fig, axes = k_subplots(num_examples)\n",
    "    plot_k_results(axes, target_probs, latent_probs, target_lang, num_examples)\n",
    "    axes[num_examples - 1].legend()\n",
    "    fig.suptitle(title)\n",
    "    plt_file = path / (exp_id + \"_k.png\")\n",
    "    fig.savefig(plt_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "    # Compute a single example\n",
    "    json_meta = {}\n",
    "    for i in range(num_examples):\n",
    "        json_meta[i] = {\n",
    "            \"input lang\": input_lang,\n",
    "            \"target lang\": target_lang,\n",
    "            \"few shot langs\": few_shot_langs,\n",
    "            \"extra langs\": extra_langs,\n",
    "            \"source prompt\": source_prompts[i],\n",
    "            \"target prompt\": target_prompts[i].prompt,\n",
    "            \"target prompt target\": target_prompts[i].target_strings,\n",
    "            \"target prompt latent\": target_prompts[i].latent_strings,\n",
    "        }\n",
    "    json_df = pd.DataFrame(json_meta)\n",
    "    with pd.option_context(\n",
    "        \"display.max_colwidth\",\n",
    "        None,\n",
    "        \"display.max_columns\",\n",
    "        None,\n",
    "        \"display.max_rows\",\n",
    "        None,\n",
    "    ):\n",
    "        display(json_df)\n",
    "    target_prompt_batch = [p.prompt for p in target_prompts[:num_examples]]\n",
    "    lang_patchscope.idx = 0\n",
    "    probs = lang_patchscope(\n",
    "        nn_model,\n",
    "        target_prompt_batch,\n",
    "        scan=True,\n",
    "    )\n",
    "    file = path / (exp_id + \"_heatmap.png\")\n",
    "    plot_topk_tokens(probs, nn_model, title=title, file=file)\n",
    "\n",
    "    meta_file = path / (exp_id + \"_heatmap.meta.json\")\n",
    "    with open(meta_file, \"w\") as f:\n",
    "        json.dump(json_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected args for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_args = [\n",
    "    (\"de\", \"it\"),\n",
    "    (\"it\", \"de\"),\n",
    "    (\"fr\", \"zh\"),\n",
    "    (\"en\", \"zh\"),\n",
    "    (\"zh\", \"fr\"),\n",
    "    (\"zh\", \"en\"),\n",
    "]\n",
    "fs_langs = [\"fr\", \"de\", \"ru\", \"en\", \"zh\", \"it\"]\n",
    "for f_args in paper_args:\n",
    "    th.cuda.empty_cache()\n",
    "    plt_lang_patch(*f_args, fs_langs, extra_langs=\"en\", exp_id=exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not paper_only:\n",
    "#     for in_lang in langs:\n",
    "#         for out_lang in langs:\n",
    "#             if in_lang == out_lang:\n",
    "#                 continue\n",
    "#             # ... more nested loops\n",
    "#             th.cuda.empty_cache()\n",
    "#             plt_lang_patch(\n",
    "#                 in_lang,\n",
    "#                 out_lang,\n",
    "#                 exp_id=exp_id,\n",
    "#             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
