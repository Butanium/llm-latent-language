{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "from random import shuffle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Fix logger bug\n",
    "import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"translation_lens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "langs = [\"fr\", \"de\", \"ru\", \"en\", \"zh\"]\n",
    "batch_size = 8\n",
    "model = \"Llama-2-7b\"\n",
    "device = \"auto\"\n",
    "# model_path = \"/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "extra_args = []\n",
    "exp_id = None\n",
    "paper_only = False\n",
    "skip_paper = False\n",
    "prob_treshold = 0.3\n",
    "map_source_lang = None\n",
    "map_source_lang_kwargs = {}\n",
    "map_target_lang = None\n",
    "map_target_lang_kwargs = {}\n",
    "use_tl = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CL Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--lens\", type=str, default=\"logit_lens\")\n",
    "parser.add_argument(\"--thinking-langs\", \"-t\", type=str, nargs=\"*\", default=[\"en\"])\n",
    "args = parser.parse_args(extra_args)\n",
    "print(f\"args: {args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "from interventions import logit_lens, patchscope_lens\n",
    "import prompt_tools\n",
    "from functools import partial\n",
    "\n",
    "model_name = model.split(\"/\")[-1]\n",
    "langs = np.array(langs)\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    use_tl=use_tl,\n",
    "    # dispatch=True,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer\n",
    "\n",
    "\n",
    "if isinstance(map_source_lang, str):\n",
    "    map_source_lang = getattr(prompt_tools, map_source_lang)\n",
    "    map_source_lang = partial(map_source_lang, **map_source_lang_kwargs)\n",
    "if isinstance(map_target_lang, str):\n",
    "    map_target_lang = getattr(prompt_tools, map_target_lang)\n",
    "    map_target_lang = partial(map_target_lang, **map_target_lang_kwargs)\n",
    "\n",
    "lens_name = args.lens\n",
    "if args.lens == \"logit_lens\":\n",
    "    lens_func = logit_lens\n",
    "elif \"patchscope\" in args.lens:\n",
    "    lens_func = patchscope_lens\n",
    "else:\n",
    "    raise ValueError(f\"Invalide method:  {args.lens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import (\n",
    "    run_prompts,\n",
    "    filter_prompts_by_prob,\n",
    "    remove_colliding_prompts,\n",
    ")\n",
    "from prompt_tools import translation_prompts\n",
    "from translation_tools import get_bn_dataset as get_translations\n",
    "\n",
    "from display_utils import (\n",
    "    plot_topk_tokens,\n",
    "    k_subplots,\n",
    "    plot_results,\n",
    "    plot_k_results,\n",
    ")\n",
    "\n",
    "\n",
    "def plot_lens_results(\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    thinking_langs=None,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    exp_id=None,\n",
    "    num_examples=9,\n",
    "):\n",
    "    if thinking_langs is None:\n",
    "        thinking_langs = []\n",
    "    thinking_langs = [l for l in thinking_langs if l != target_lang]\n",
    "    df = get_translations(\n",
    "        input_lang,\n",
    "        [target_lang, *thinking_langs],\n",
    "        num_words=num_words,\n",
    "    )\n",
    "    no_proc = []\n",
    "    if map_source_lang is not None:\n",
    "        df[input_lang + \" no proc\"] = df[input_lang]\n",
    "        df[input_lang] = df[input_lang].apply(map_source_lang)\n",
    "        no_proc.append(input_lang + \" no proc\")\n",
    "    if map_target_lang is not None:\n",
    "        df[target_lang + \" no proc\"] = df[target_lang]\n",
    "        df[target_lang] = df[target_lang].apply(map_target_lang)\n",
    "        no_proc.append(target_lang + \" no proc\")\n",
    "    target_prompts = translation_prompts(\n",
    "        df, tokenizer, input_lang, target_lang, thinking_langs + no_proc, augment_tokens=False\n",
    "    )\n",
    "    target_prompts = remove_colliding_prompts(target_prompts, ignore_langs=no_proc)\n",
    "    print(f\"Number of non-colliding prompts: {len(target_prompts)}\")\n",
    "    target_prompts = filter_prompts_by_prob(\n",
    "        target_prompts, nn_model, prob_treshold, batch_size=batch_size\n",
    "    )\n",
    "    print(f\"Number of prompts after filtering: {len(target_prompts)}\")\n",
    "    if len(target_prompts) < num_examples:\n",
    "        print(\"Not enough prompts after filtering\")\n",
    "        return\n",
    "    \n",
    "    if len(target_prompts) == 0:\n",
    "        print(f\"No prompts left after filtering for {input_lang} -> {target_lang}\")\n",
    "        return\n",
    "\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, get_probs=lens_func\n",
    "    )\n",
    "\n",
    "    json_dic = {\n",
    "        target_lang: target_probs.tolist(),\n",
    "    }\n",
    "    for label, probs in latent_probs.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    pref = \"_\".join([])\n",
    "    path = (\n",
    "        Path(\"results\")\n",
    "        / model_name\n",
    "        / exp_name\n",
    "        / (f\"{pref}-{input_lang}_{target_lang}-\")\n",
    "    )\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (exp_id + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "    # fig, (ax, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    pref = pref.replace(\"_\", \" \")\n",
    "    title = (\n",
    "        f\"{model_name}: {exp_name} from ({pref}) into ({input_lang} -> {target_lang})\"\n",
    "    )\n",
    "    plot_results(ax, target_probs, latent_probs, target_lang)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (exp_id + \".png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot k examples\n",
    "    fig, axes = k_subplots(num_examples)\n",
    "    plot_k_results(axes, target_probs, latent_probs, target_lang, num_examples)\n",
    "    axes[num_examples - 1].legend()\n",
    "    fig.suptitle(title)\n",
    "    plt_file = path / (exp_id + \"_k.png\")\n",
    "    fig.savefig(plt_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "    # Compute a single example\n",
    "    json_meta = {}\n",
    "    for i in range(num_examples):\n",
    "        json_meta[i] = {\n",
    "            \"input lang\": input_lang,\n",
    "            \"target lang\": target_lang,\n",
    "            \"target prompt\": target_prompts[i].prompt,\n",
    "            \"target prompt target\": target_prompts[i].target_strings,\n",
    "            \"target prompt latent\": target_prompts[i].latent_strings,\n",
    "        }\n",
    "    json_df = pd.DataFrame(json_meta)\n",
    "    with pd.option_context(\n",
    "        \"display.max_colwidth\",\n",
    "        None,\n",
    "        \"display.max_columns\",\n",
    "        None,\n",
    "        \"display.max_rows\",\n",
    "        None,\n",
    "    ):\n",
    "        display(json_df)\n",
    "    target_prompt_batch = [p.prompt for p in target_prompts[:num_examples]]\n",
    "    probs = lens_func(\n",
    "        nn_model,\n",
    "        target_prompt_batch,\n",
    "        scan=True,\n",
    "    )\n",
    "    file = path / (exp_id + \"_heatmap.png\")\n",
    "    plot_topk_tokens(probs, nn_model, title=title, file=file)\n",
    "\n",
    "    meta_file = path / (exp_id + \"_heatmap.meta.json\")\n",
    "    with open(meta_file, \"w\") as f:\n",
    "        json.dump(json_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected args for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_args = [[\"fr\", \"en\"], [\"en\", \"fr\"], [\"en\", \"de\"], [\"de\", \"en\"]]\n",
    "paper_args = [[\"de\", \"it\"]]\n",
    "# paper_args = [[\"fr\", \"zh\"], [\"it\", \"de\"], [\"de\", \"it\"], ] # [\"zh\", \"ru\"], [\"fr\", \"de\"], [\"zh\", \"fi\"]]\n",
    "if not skip_paper:\n",
    "    for f_args in paper_args:\n",
    "        th.cuda.empty_cache()\n",
    "        plot_lens_results(*f_args, exp_id=exp_id, extra_langs=args.thinking_langs.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not paper_only:\n",
    "    for in_lang in langs:\n",
    "        for out_lang in langs:\n",
    "            if in_lang == out_lang:\n",
    "                continue\n",
    "            th.cuda.empty_cache()\n",
    "            plot_lens_results(\n",
    "                in_lang,\n",
    "                out_lang,\n",
    "                exp_id=exp_id,\n",
    "                extra_langs=args.thinking_langs,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
