{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "from random import shuffle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Fix logger bug\n",
    "import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"Logit Lens on Definitions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "langs = [\"fr\", \"de\", \"ru\", \"en\", \"zh\"]\n",
    "batch_size = 8\n",
    "model = \"Llama-2-7b\"\n",
    "device = \"auto\"\n",
    "# model_path = \"/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "extra_args = []\n",
    "exp_id = None\n",
    "paper_only = False\n",
    "prob_treshold = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CL Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--thinking-langs\", nargs=\"+\", default=[\"en\"])\n",
    "args = parser.parse_args(extra_args)\n",
    "print(f\"args: {args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "\n",
    "model_name = model.split(\"/\")[-1]\n",
    "langs = np.array(langs)\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    # dispatch=True,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import (\n",
    "    run_prompts,\n",
    "    filter_prompts_by_prob,\n",
    "    remove_colliding_prompts,\n",
    "    logit_lens,\n",
    ")\n",
    "from translation_tools import cloze_prompts\n",
    "from translation_tools import get_cloze_dataset\n",
    "\n",
    "from utils import plot_ci, plot_k, plot_topk_tokens, k_subplots, ulist\n",
    "\n",
    "\n",
    "def logit_lens_plots(\n",
    "    lang,\n",
    "    thinking_langs=args.thinking_langs,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    exp_id=None,\n",
    "    num_examples=9,\n",
    "):\n",
    "    \"\"\"\n",
    "    func docstring\n",
    "    \"\"\"\n",
    "    if thinking_langs is None:\n",
    "        thinking_langs = []\n",
    "    df = get_cloze_dataset(ulist([lang, *thinking_langs]), num_words=num_words)\n",
    "    df = df[df[f\"definitions_wo_ref_{lang}\"].map(lambda x: x != [])]\n",
    "    target_prompts = cloze_prompts(df, tokenizer, lang, thinking_langs)\n",
    "    target_prompts = remove_colliding_prompts(target_prompts, ignore_langs=f\"source_{lang}\")\n",
    "    target_prompts = filter_prompts_by_prob(\n",
    "        target_prompts, nn_model, prob_treshold, batch_size=batch_size\n",
    "    )\n",
    "    if len(target_prompts) < num_examples:\n",
    "        print(\n",
    "            f\"Skipping {lang} because only {len(target_prompts)} prompts available\"\n",
    "        )\n",
    "        return\n",
    "    print(f\"Found {len(df)} definitions for {lang}\")\n",
    "\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, get_probs=logit_lens\n",
    "    )\n",
    "\n",
    "    json_dic = {\n",
    "        lang: target_probs.tolist(),\n",
    "    }\n",
    "    for label, probs in latent_probs.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    thinking_str = \"_\".join(thinking_langs)\n",
    "    path = (\n",
    "        Path(\"results\")\n",
    "        / model_name\n",
    "        / exp_name\n",
    "        / (f\"{lang}--{thinking_str}\")\n",
    "    )\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (exp_id + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "    # fig, (ax, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    colors = sns.color_palette(\"tab10\", 1 + len(latent_probs))\n",
    "    thinking_str = thinking_str.replace(\"_\", \" \")\n",
    "    title = (\n",
    "        f\"{model_name}: {exp_name} {lang}\"\n",
    "    )\n",
    "    plot_ci(ax, target_probs, label=lang, color=colors[0])\n",
    "    for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "        plot_ci(ax, probs, label=label, color=colors[i + 1], init=False)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (exp_id + \".png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot k examples\n",
    "    fig, axes = k_subplots(num_examples)\n",
    "    plot_k(\n",
    "        axes,\n",
    "        target_probs[:num_examples],\n",
    "        label=lang,\n",
    "        color=colors[0],\n",
    "        k=num_examples,\n",
    "    )\n",
    "    for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "        plot_k(\n",
    "            axes,\n",
    "            probs[:num_examples],\n",
    "            label=label,\n",
    "            color=colors[i + 1],\n",
    "            init=False,\n",
    "            k=num_examples,\n",
    "        )\n",
    "    axes[num_examples - 1].legend()\n",
    "    fig.suptitle(title)\n",
    "    plt_file = path / (exp_id + \"_k.png\")\n",
    "    fig.savefig(plt_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "    # Compute a single example\n",
    "    json_meta = {}\n",
    "    for i in range(num_examples):\n",
    "        json_meta[i] = {\n",
    "            \"definition lang\": lang,\n",
    "            \"target prompt\": target_prompts[i].prompt,\n",
    "            \"target prompt target\": target_prompts[i].target_strings,\n",
    "            \"target prompt latent\": target_prompts[i].latent_strings,\n",
    "        }\n",
    "    json_df = pd.DataFrame(json_meta)\n",
    "    with pd.option_context(\n",
    "        \"display.max_colwidth\",\n",
    "        None,\n",
    "        \"display.max_columns\",\n",
    "        None,\n",
    "        \"display.max_rows\",\n",
    "        None,\n",
    "    ):\n",
    "        display(json_df)\n",
    "    target_prompt_batch = [p.prompt for p in target_prompts[:num_examples]]\n",
    "    probs = logit_lens(\n",
    "        nn_model,\n",
    "        target_prompt_batch,\n",
    "        scan=True,\n",
    "    )\n",
    "    file = path / (exp_id + \"_heatmap.png\")\n",
    "    plot_topk_tokens(probs, nn_model, title=title, file=file)\n",
    "\n",
    "    meta_file = path / (exp_id + \"_heatmap.meta.json\")\n",
    "    with open(meta_file, \"w\") as f:\n",
    "        json.dump(json_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected args for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_args = []\n",
    "for args_ in paper_args:\n",
    "    th.cuda.empty_cache()\n",
    "    logit_lens_plots(*args_, exp_id=exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not paper_only:\n",
    "    for lang in langs:\n",
    "        th.cuda.empty_cache()\n",
    "        logit_lens_plots(\n",
    "            lang,\n",
    "            exp_id=exp_id,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
