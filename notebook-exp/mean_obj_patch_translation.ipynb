{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "from random import shuffle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Fix logger bug\n",
    "import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"mean_obj_patching\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "langs = [\"fr\", \"de\", \"ru\", \"en\", \"zh\"]\n",
    "batch_size = 8\n",
    "model = \"Llama-2-7b\"\n",
    "device = \"auto\"\n",
    "# model_path = \"/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "num_patches = -1\n",
    "extra_args = []\n",
    "exp_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--inp-langs\", \"-il\", nargs=\"+\", default=langs)\n",
    "parser.add_argument(\"--out-langs\", \"-ol\", nargs=\"+\", default=langs)\n",
    "parser.add_argument(\"--paper-only\", \"-po\", action=\"store_true\")\n",
    "args = parser.parse_args(extra_args)\n",
    "print(f\"args: {args}\")\n",
    "\n",
    "\n",
    "langs = np.array(langs)\n",
    "out_langs = {lang: np.array([l for l in out_langs if l != lang]) for lang in langs}\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    # dispatch=True,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import (\n",
    "    run_prompts,\n",
    "    object_lens,\n",
    "    collect_activations,\n",
    "    get_num_layers,\n",
    ")\n",
    "from translation_tools import translation_prompts\n",
    "from translation_tools import get_bn_dataset as get_translations\n",
    "\n",
    "from utils import plot_ci, plot_k, plot_topk_tokens, ulist\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def get_id_to_patch(sample_prompt):\n",
    "    split = sample_prompt.split('\"')\n",
    "    start = '\"'.join(split[:-2])\n",
    "    end = '\"' + '\"'.join(split[-2:])\n",
    "    tok_start = tokenizer.encode(start, add_special_tokens=False)\n",
    "    tok_end = tokenizer.encode(end, add_special_tokens=False)\n",
    "    full = tokenizer.encode(sample_prompt, add_special_tokens=False)\n",
    "    if tok_start + tok_end != full:\n",
    "        raise ValueError(\"This is weird, check code\")\n",
    "    idx = -len(tok_end) - 1\n",
    "    return idx\n",
    "\n",
    "\n",
    "def object_patching_plot(\n",
    "    source_lang_pairs,\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    extra_langs=None,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    num_pairs=200,\n",
    "    exp_id=None,\n",
    "    k=4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Patchscope with source hidden from:\n",
    "    index -1 and Prompt = mean source_input_lang: A -> source_target_lang:\n",
    "    Into target prompt:\n",
    "    into index = -1, prompt = input_lang: A -> target_lang:\n",
    "    Then plot with latent_langs, target_lang, source_target_lang\n",
    "    \"\"\"\n",
    "    source_lang_pairs = np.array(source_lang_pairs)\n",
    "    if extra_langs is None:\n",
    "        extra_langs = []\n",
    "    if isinstance(extra_langs, str):\n",
    "        extra_langs = [extra_langs]\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    global source_df, target_df, target_prompts, target_probs, latent_probs, source_prompts, _source_prompts, _target_prompts\n",
    "    if exp_id is None:\n",
    "        exp_id = str(int(time()))\n",
    "    else:\n",
    "        exp_id = str(exp_id)\n",
    "    source_df = get_translations(\n",
    "        target_lang,\n",
    "        [*source_lang_pairs.flatten(), input_lang],\n",
    "        num_words,\n",
    "    )\n",
    "    target_df = get_translations(\n",
    "        input_lang,\n",
    "        [*source_lang_pairs.flatten(), target_lang],\n",
    "        num_words,\n",
    "    )\n",
    "\n",
    "    _source_prompts = list(\n",
    "        zip(\n",
    "            *[\n",
    "                translation_prompts(\n",
    "                    source_df,\n",
    "                    nn_model.tokenizer,\n",
    "                    inp_lang,\n",
    "                    targ_lang,\n",
    "                    [target_lang],\n",
    "                    augment_tokens=False,\n",
    "                )\n",
    "                for inp_lang, targ_lang in source_lang_pairs\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    _target_prompts = translation_prompts(\n",
    "        target_df,\n",
    "        nn_model.tokenizer,\n",
    "        input_lang,\n",
    "        target_lang,\n",
    "        [],# [*list(zip(*source_lang_pairs))[1], *extra_langs],\n",
    "        augment_tokens=False,\n",
    "    )\n",
    "\n",
    "    collected_pairs = 0\n",
    "    source_prompts = []\n",
    "    target_prompts = []\n",
    "    source_target = list(itertools.product(source_df.iterrows(), target_df.iterrows()))\n",
    "    shuffle(source_target)\n",
    "\n",
    "    for (i, source_row), (j, target_row) in source_target:\n",
    "        if source_row[\"word_original\"] == target_row[\"word_original\"]:\n",
    "            continue\n",
    "        src_p = _source_prompts[i]\n",
    "        targ_p = deepcopy(_target_prompts[j])\n",
    "        assert (\n",
    "            src_p[0].latent_tokens[target_lang] == src_p[1].latent_tokens[target_lang]\n",
    "        ), \"check code\"\n",
    "        latent_tokens = {f\"source_{target_lang}\": src_p[0].latent_tokens[target_lang]}\n",
    "        # latent_tokens[f\"sources\"] = ulist(\n",
    "        #     sum([p.target_tokens for p in src_p], [])\n",
    "        # )\n",
    "        latent_tokens.update(**targ_p.latent_tokens)\n",
    "        targ_p.latent_tokens = latent_tokens\n",
    "        targ_p.latent_strings[f\"sources\"] = ulist(\n",
    "            sum([p.target_strings for p in src_p], [])\n",
    "        )\n",
    "        targ_p.latent_strings[f\"source_{target_lang}\"] = src_p[0].latent_strings[\n",
    "            target_lang\n",
    "        ]\n",
    "        if targ_p.has_no_collisions():\n",
    "            source_prompts.append(src_p)\n",
    "            target_prompts.append(targ_p)\n",
    "            collected_pairs += 1\n",
    "        if collected_pairs >= num_pairs:\n",
    "            break\n",
    "    if collected_pairs < num_pairs:\n",
    "        print(\n",
    "            f\"Could only collect {collected_pairs} pairs for {source_lang_pairs.tolist()} - {input_lang} -> {target_lang}, skipping...\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    source_prompts_str = [\n",
    "        ['\"'.join(p.prompt.split('\"')[:-2]) for p in ps] for ps in source_prompts\n",
    "    ]\n",
    "    idx = get_id_to_patch(target_prompts[0].prompt)\n",
    "\n",
    "    def object_patching(nn_model, prompt_batch, scan, source_prompt_batch=None):\n",
    "        offset = object_patching.offset\n",
    "        batch_size = len(prompt_batch)\n",
    "        if source_prompt_batch is None:\n",
    "            source_prompt_batch = source_prompts_str[offset : offset + batch_size]\n",
    "        source_prompt_batch = sum(source_prompt_batch, [])\n",
    "        dataloader = DataLoader(source_prompt_batch, batch_size=batch_size)\n",
    "        hiddens = []\n",
    "        for batch in dataloader:\n",
    "            acts = collect_activations(nn_model, batch)\n",
    "            hiddens.append(th.stack(acts).transpose(0, 1))\n",
    "        hiddens = th.cat(hiddens, dim=0)  # (all_prompts, layer, hidden_size)\n",
    "        hiddens = hiddens.reshape(\n",
    "            batch_size, len(source_prompts_str[0]), get_num_layers(nn_model), -1\n",
    "        ).mean(\n",
    "            dim=1\n",
    "        )  # (batch_size, num_layers, hidden_size)\n",
    "        hiddens = hiddens.transpose(0, 1)  # (num_layers, batch_size, hidden_size)\n",
    "        object_patching.offset += batch_size\n",
    "        return object_lens(\n",
    "            nn_model,\n",
    "            prompt_batch,\n",
    "            idx,\n",
    "            hiddens=hiddens,\n",
    "            scan=scan,\n",
    "            num_patches=num_patches,\n",
    "        )\n",
    "\n",
    "    object_patching.offset = 0\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, method=object_patching\n",
    "    )\n",
    "\n",
    "    # # Get the baseline to normalize the plots\n",
    "    # source_prompts_probs, _ = run_prompts(\n",
    "    #     nn_model, source_prompts, batch_size=batch_size, method=\"next_token_probs\"\n",
    "    # )\n",
    "    # source_prompts_baseline = source_prompts_probs.mean()\n",
    "    # target_prompts_probs, _ = run_prompts(\n",
    "    #     nn_model, target_prompts, batch_size=batch_size, method=\"next_token_probs\"\n",
    "    # )\n",
    "    # target_prompts_baseline = target_prompts_probs.mean()\n",
    "\n",
    "    json_dic = {\n",
    "        target_lang: target_probs.tolist(),\n",
    "        # \"source prompt probs\": source_prompts_probs.squeeze().tolist(),\n",
    "        # \"target prompt probs\": target_prompts_probs.squeeze().tolist(),\n",
    "    }\n",
    "    for label, probs in latent_probs.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    pref = \"_\".join(\"-\".join(ls) for ls in source_lang_pairs)\n",
    "    path = (\n",
    "        Path(\"results\")\n",
    "        / model_name\n",
    "        / exp_name\n",
    "        / (f\"{pref}-{input_lang}_{target_lang}-\")\n",
    "    )\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (exp_id + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig, ax2 = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    colors = sns.color_palette(\"tab10\", 1 + len(latent_probs))\n",
    "    # plot_ci(\n",
    "    #     ax1, target_probs / target_prompts_baseline, label=target_lang, color=colors[0]\n",
    "    # )\n",
    "    # for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "    #     if \"source\" in label:\n",
    "    #         baseline = source_prompts_baseline\n",
    "    #     else:\n",
    "    #         baseline = target_prompts_baseline\n",
    "    #     plot_ci(ax1, probs / baseline, label=label, color=colors[i + 1], init=False)\n",
    "    # ax1.legend()\n",
    "    pref = pref.replace(\"_\", \" \")\n",
    "    title = f\"{model_name}: ObjPatch from ({pref}) into ({input_lang} -> {target_lang})\"\n",
    "    # ax1.set_title(title)\n",
    "\n",
    "    # Raw probabilities plot\n",
    "    plot_ci(ax2, target_probs, label=target_lang, color=colors[0])\n",
    "    for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "        plot_ci(ax2, probs, label=label, color=colors[i + 1], init=False)\n",
    "    ax2.legend()\n",
    "    ax2.set_title(title + \" - Raw probs\")\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (exp_id + \".png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot k examples\n",
    "    fig, axes = plt.subplots(1, k, figsize=(5 * k, 5))\n",
    "    plot_k(\n",
    "        axes,\n",
    "        target_probs[:k],\n",
    "        label=target_lang,\n",
    "        color=colors[0],\n",
    "        k=k,\n",
    "    )\n",
    "    for i, (label, probs) in enumerate(latent_probs.items()):\n",
    "        plot_k(\n",
    "            axes,\n",
    "            probs[:k],\n",
    "            label=label,\n",
    "            color=colors[i + 1],\n",
    "            init=False,\n",
    "            k=k,\n",
    "        )\n",
    "    axes[-1].legend()\n",
    "    fig.suptitle(title + \" - Raw probs\")\n",
    "    plt_file = path / (exp_id + \"_k.png\")\n",
    "    fig.savefig(plt_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "    # Compute a single example\n",
    "    json_meta = {}\n",
    "    for i in range(k):\n",
    "        json_meta[i] = {\n",
    "            \"source pairs\": source_lang_pairs.tolist(),\n",
    "            \"input lang\": input_lang,\n",
    "            \"target lang\": target_lang,\n",
    "            \"source prompt\": {\n",
    "                \"-\".join(l): source_prompts_str[i][j]\n",
    "                for j, l in enumerate(source_lang_pairs)\n",
    "            },\n",
    "            \"source prompt target\": {\n",
    "                \"-\".join(l): source_prompts[i][j].target_strings\n",
    "                for j, l in enumerate(source_lang_pairs)\n",
    "            },\n",
    "            \"source prompt latent\": {\n",
    "                \"-\".join(l): source_prompts[i][j].latent_strings\n",
    "                for j, l in enumerate(source_lang_pairs)\n",
    "            },\n",
    "            \"target prompt\": target_prompts[i].prompt,\n",
    "            \"target prompt target\": target_prompts[i].target_strings,\n",
    "            \"target prompt latent\": target_prompts[i].latent_strings,\n",
    "        }\n",
    "    json_df = pd.DataFrame(json_meta)\n",
    "    with pd.option_context(\n",
    "        \"display.max_colwidth\",\n",
    "        None,\n",
    "        \"display.max_columns\",\n",
    "        None,\n",
    "        \"display.max_rows\",\n",
    "        None,\n",
    "    ):\n",
    "        display(json_df)\n",
    "    target_prompt_batch = [p.prompt for p in target_prompts[:k]]\n",
    "    probs = object_patching(\n",
    "        nn_model,\n",
    "        target_prompt_batch,\n",
    "        scan=True,\n",
    "        source_prompt_batch=source_prompts_str[:k],\n",
    "    )\n",
    "    file = path / (exp_id + \"_heatmap.png\")\n",
    "    plot_topk_tokens(probs, nn_model, title=title, file=file)\n",
    "\n",
    "    meta_file = path / (exp_id + \"_heatmap.meta.json\")\n",
    "    with open(meta_file, \"w\") as f:\n",
    "        json.dump(json_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_args = [\n",
    "    (\n",
    "        [(\"de\", \"fr\"), (\"es\", \"hi\"), (\"ru\", \"de\"), (\"ja\", \"en\"), (\"it\", \"ko\"),\n",
    "         (\"de\", \"hi\"), (\"es\", \"fi\"), (\"ru\", \"nl\"), (\"ja\", \"de\"), (\"it\", \"ru\")],\n",
    "        \"fr\",\n",
    "        \"zh\",\n",
    "    ),\n",
    "    (\n",
    "        [(\"de\", \"fr\"), (\"nl\", \"fi\"), (\"zh\", \"es\"), (\"es\", \"ru\"), (\"ru\", \"ko\")],\n",
    "        \"fr\",\n",
    "        \"zh\"\n",
    "    )\n",
    "    # (\n",
    "    #     [\"fr\", \"ko\", \"hi\"],\n",
    "    #     \"en\",\n",
    "    #     \"de\",\n",
    "    #     \"zh\",\n",
    "    # ),\n",
    "    # (\n",
    "    #     [\"ru\", \"de\", \"ja\"],\n",
    "    #     \"en\",\n",
    "    #     \"fr\",\n",
    "    #     \"zh\",\n",
    "    # ),\n",
    "    # (\"zh\", \"en\", \"fr\", \"de\",),\n",
    "]\n",
    "for args in paper_args:\n",
    "    object_patching_plot(*args, exp_id=exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not paper_only:\n",
    "    for source_target_lang in langs:\n",
    "        for in_lang in langs:\n",
    "            for out_lang in out_langs[in_lang]:\n",
    "                th.cuda.empty_cache()\n",
    "                object_patching_plot(\n",
    "                    [\n",
    "                        (l, source_target_lang)\n",
    "                        for l in inp_langs\n",
    "                        if l != source_target_lang and l != in_lang\n",
    "                    ],\n",
    "                    in_lang,\n",
    "                    out_lang,\n",
    "                    exp_id=exp_id,\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
