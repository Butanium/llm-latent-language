{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "from random import shuffle\n",
    "from torch.utils.data import DataLoader\n",
    "from display_utils import plot_topk_tokens\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"latent_prompting\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model = \"Llama-2-7b\"\n",
    "device = \"auto\"\n",
    "model_path = \"/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf\"\n",
    "trust_remote_code = False\n",
    "use_tl = False\n",
    "extra_args = []\n",
    "exp_id = None\n",
    "remote = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--single-layer\", \"-sl\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--patch-from-layer\", \"-fl\", type=int, default=None)\n",
    "parser.add_argument(\"--patch-until-layer\", \"-tl\", type=int, default=None)\n",
    "parser.add_argument(\"--rnd-labels\", \"-rl\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--link-string\", type=str, default=\"->\")\n",
    "parser.add_argument(\"--try-gt-labels\", \"-gt\", action=\"store_true\", default=False)\n",
    "args = parser.parse_args(extra_args)\n",
    "print(f\"args: {args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and arg preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "\n",
    "model_name = model.split(\"/\")[-1]\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    use_tl=use_tl,\n",
    "    # dispatch=True,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer\n",
    "latent_kwargs = dict(\n",
    "    collect_from_single_layer=args.single_layer,\n",
    "    patch_from_layer=args.patch_from_layer,\n",
    "    patch_until_layer=args.patch_until_layer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_path = Path(\"cache/filtered_fw_sample-10BT\")\n",
    "if not fw_path.exists():\n",
    "    fw_path.parent.mkdir(exist_ok=True)\n",
    "    # load dataset\n",
    "    fw_dataset = load_dataset(\n",
    "        \"HuggingFaceFW/fineweb\", name=\"sample-10BT\", split=\"train\"\n",
    "    )\n",
    "    print(len(fw_dataset))\n",
    "    fw_dataset = fw_dataset.filter(\n",
    "        lambda x: len(x[\"text\"].split(\" \")) < 250 and len(x[\"text\"]) < 2000\n",
    "    ).shuffle(seed=42)\n",
    "    print(len(fw_dataset))\n",
    "    fw_dataset.save_to_disk(fw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight_utils import collect_activations_batched, project_on_vocab\n",
    "\n",
    "\n",
    "def process_dataset(dataset_type, trn_n, val_n=None):\n",
    "    dataset_path = Path(f\"cache/{dataset_type}_dataset\")\n",
    "    act_path = Path(\"cache\") / f\"fw_{dataset_type}_acts\" / f\"{model_name}.pt\"\n",
    "    if not dataset_path.exists():\n",
    "        print(f\"Creating {dataset_type} dataset\")\n",
    "        fw_dataset = load_from_disk(fw_path)\n",
    "        if dataset_type == \"train\":\n",
    "            fw_subset = fw_dataset[\"text\"][:trn_n]\n",
    "        else:\n",
    "            fw_subset = fw_dataset[\"text\"][trn_n : trn_n + val_n]\n",
    "\n",
    "        data = {\"text\": [], \"gt\": []}\n",
    "        for sample in fw_subset:\n",
    "            toks = tokenizer.encode(sample, add_special_tokens=False)\n",
    "            rnd_idx = np.random.randint(0, len(toks) - 1)\n",
    "            x = tokenizer.decode(toks[:rnd_idx])\n",
    "            y = toks[rnd_idx]\n",
    "            data[\"text\"].append(x)\n",
    "            data[\"gt\"].append(y)\n",
    "        dataset = Dataset.from_dict(data)\n",
    "        dataset.save_to_disk(dataset_path)\n",
    "    else:\n",
    "        dataset = load_from_disk(dataset_path)\n",
    "\n",
    "    if act_path.exists():\n",
    "        fw_acts = th.load(act_path)\n",
    "    else:\n",
    "        print(\"Collecting activations\")\n",
    "        act_path.parent.mkdir(exist_ok=True)\n",
    "        fw_acts = collect_activations_batched(\n",
    "            nn_model,\n",
    "            dataset[\"text\"],\n",
    "            batch_size=batch_size,\n",
    "            tqdm=tqdm,\n",
    "            remote=remote,\n",
    "        )\n",
    "        th.save(fw_acts, act_path)\n",
    "\n",
    "    print(f\"Adding model predictions to {dataset_type} dataset\")\n",
    "    with nn_model.trace(\"a\", remote=remote):\n",
    "        model_preds = (\n",
    "            project_on_vocab(nn_model, fw_acts[-1].to(\"cuda:0\"))\n",
    "            .argmax(-1)\n",
    "            .cpu()\n",
    "            .tolist()\n",
    "            .save()\n",
    "        )\n",
    "    dataset = dataset.add_column(model_name, model_preds.value)\n",
    "    return dataset, fw_acts\n",
    "\n",
    "\n",
    "# Process validation dataset\n",
    "val_dataset, fw_val_acts = process_dataset(\"val\", trn_n=10000, val_n=2000)\n",
    "\n",
    "# Process training dataset\n",
    "train_dataset, fw_train_acts = process_dataset(\"train\", trn_n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot patchscope lens eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_tools import Prompt\n",
    "from exp_tools import run_prompts\n",
    "\n",
    "prompts = []\n",
    "for i, data in enumerate(val_dataset):\n",
    "    prompts.append(\n",
    "        Prompt(\n",
    "            data[\"text\"],\n",
    "            [data[\"gt\"]],\n",
    "            {\"model pred\": [data[model_name]]},\n",
    "            [tokenizer.convert_ids_to_tokens(data[\"gt\"])],\n",
    "            {\"model pred\": [tokenizer.convert_ids_to_tokens(data[model_name])]},\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interventions import LatentPrompt, LatentPromptBatch, latent_prompt_lens\n",
    "\n",
    "\n",
    "def fs_latent_prompt(num_fs):\n",
    "    base_str = (\n",
    "        f\"{tokenizer.bos_token}{args.link_string}{tokenizer.unk_token}\\n\" * num_fs\n",
    "    )\n",
    "    base_str += f\"{tokenizer.bos_token}{args.link_string}\"\n",
    "    return LatentPrompt.from_string(base_str, tokenizer)\n",
    "\n",
    "\n",
    "class TokenGenerator:\n",
    "    def __init__(self, tokens, repeat=0):\n",
    "        self.tokens = tokens\n",
    "        self.idx = list(range(len(tokens)))[::-1]\n",
    "        self.last_chosen = []\n",
    "        self.repeat = repeat\n",
    "        self.current_repeat = 0\n",
    "\n",
    "    def pop(self, *_args, **_kwargs):\n",
    "        if self.idx == []:\n",
    "            self.idx = list(range(len(self.tokens)))\n",
    "            shuffle(self.idx)\n",
    "        self.current_repeat += 1\n",
    "        if self.current_repeat <= self.repeat:\n",
    "            self.last_chosen.append(self.last_chosen[-1])\n",
    "            return self.last_chosen[-1]\n",
    "        self.current_repeat = 0\n",
    "        id_ = self.idx.pop()\n",
    "        if id_ in self.last_chosen:\n",
    "            self.idx.insert(id_, 0)\n",
    "            return self.pop()\n",
    "        self.last_chosen.append(id_)\n",
    "        return self.tokens[id_]\n",
    "\n",
    "    def collect(self):\n",
    "        res = self.last_chosen\n",
    "        self.last_chosen = []\n",
    "        return res\n",
    "\n",
    "    def reset(self):\n",
    "        self.idx = list(range(len(self.tokens)))[::-1]\n",
    "        self.last_chosen = []\n",
    "\n",
    "\n",
    "class PromptBatchGenerator:\n",
    "    def __init__(\n",
    "        self, tokens, token_placeholder: int = tokenizer.unk_token_id, repeat=0\n",
    "    ):\n",
    "        self.token_generator = TokenGenerator(tokens, repeat=repeat)\n",
    "        self.token_placeholder = token_placeholder\n",
    "\n",
    "    def batch(self, latent_prompt, num_prompts):\n",
    "        batch = LatentPromptBatch.from_latent_prompts(\n",
    "            [latent_prompt] * num_prompts, tokenizer\n",
    "        ).replace_tokens(self.token_placeholder, self.token_generator)\n",
    "        idx = self.token_generator.collect()\n",
    "        return batch, idx\n",
    "\n",
    "\n",
    "def latent_prompting(nn_model, prompts, scan=True, *, generator, num_fs, **kwargs):\n",
    "    latent_batch, c_idx = generator.batch(fs_latent_prompt(num_fs), len(prompts))\n",
    "    print(f\"using c_idx {c_idx}\")\n",
    "    acts = fw_train_acts[:, c_idx]\n",
    "    idx = latent_prompting.idx\n",
    "    latents = []\n",
    "    for i in range(len(prompts)):\n",
    "        if num_fs > 0:\n",
    "            latents.append(acts[:, i * num_fs : (i + 1) * num_fs])\n",
    "        latents.append(fw_val_acts[:, idx + i].unsqueeze(1))\n",
    "    print(f\"{len(latents)} latents, {len(prompts)} prompts\")\n",
    "    latent_prompting.idx += len(prompts)\n",
    "    latents = th.cat(latents, dim=1)\n",
    "    return latent_prompt_lens(\n",
    "        nn_model, latent_batch, latents=latents, scan=scan, remote=remote, **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from display_utils import plot_results\n",
    "\n",
    "\n",
    "def fsp_plot(\n",
    "    nfs,\n",
    "    fs_token_name,\n",
    "    fs_tokens,\n",
    "    n=100,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    **lp_lens_kwargs,\n",
    "):\n",
    "    if shuffle:\n",
    "        fs_tokens = fs_tokens.copy()\n",
    "        shuffle(fs_tokens)\n",
    "    generator = PromptBatchGenerator(fs_tokens)\n",
    "    latent_prompting.idx = 0\n",
    "    pr, lpr = list(\n",
    "        run_prompts(\n",
    "            nn_model,\n",
    "            prompts[:n],\n",
    "            get_probs=latent_prompting,\n",
    "            batch_size=batch_size,\n",
    "            tqdm=tqdm,\n",
    "            method_kwargs={\"generator\": generator, \"num_fs\": nfs, **lp_lens_kwargs},\n",
    "        )\n",
    "    )\n",
    "    json_dic = {\n",
    "        \"next token\": pr.tolist(),\n",
    "        \"num_fs\": nfs,\n",
    "        \"kwargs\": lp_lens_kwargs,\n",
    "    }\n",
    "    for label, probs in lpr.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    path = Path(\"results\") / model_name / exp_name / (f\"{nfs}_{fs_token_name}\")\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (exp_id + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "    lpr = {f\"{nfs}-{fs_token_name} {k}\": v for k, v in lpr.items()}\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_results(\n",
    "        ax,\n",
    "        pr,\n",
    "        lpr,\n",
    "        f\"{nfs} few-shot - {fs_token_name} labels\",\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_xlabel(\"Layer\")\n",
    "    ax.set_title(f\"{model_name} - {nfs}-{fs_token_name}\")\n",
    "    plt.savefig(path / (exp_id + \".png\"))\n",
    "    plt.show()\n",
    "    return pr, lpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_tokens = train_dataset[\"gt\"].copy()\n",
    "pred_tokens = train_dataset[model_name].copy()\n",
    "num_few_shot = [0, 5, 10, 50, 100, 500]\n",
    "batch_sizes = [1024, 128, 128, 64, 32, 16]\n",
    "lat_exp_probs = {}\n",
    "fs_tokens = [pred_tokens, gt_tokens] if args.try_gt_labels else [pred_tokens]\n",
    "for fs_token, fs_token_name in zip(fs_tokens, [\"model pred\", \"gt\"]):\n",
    "    for nfs, bs in zip(num_few_shot, batch_sizes):\n",
    "        lat_exp_probs[nfs, fs_token_name] = fsp_plot(\n",
    "            nfs,\n",
    "            fs_token_name,\n",
    "            fs_token,\n",
    "            n=100,\n",
    "            batch_size=bs,\n",
    "            shuffle=args.rnd_labels,\n",
    "            **latent_kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from display_utils import plot_ci\n",
    "# Plot all configs together\n",
    "fig, ax = plt.subplots()\n",
    "for (nfs, fs_token_name), (pr, _) in lat_exp_probs.items():\n",
    "    plot_ci(ax, pr, label=f\"{nfs}-{fs_token_name}\")\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xlabel(\"Layer\")\n",
    "ax.set_title(f\"{model_name} - all\")\n",
    "plt.savefig(Path(\"results\") / model_name / exp_name / (exp_id + \"_all.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
