{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from nnsight import LanguageModel, CONFIG\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch as th\n",
    "import torch  # for those who are afraid of th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from warnings import warn\n",
    "from random import shuffle, sample\n",
    "# Fix logger bug\n",
    "#Â import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "th.set_grad_enabled(False)\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 18:43:04,002 [babelnet.conf] INFO: Loaded configuration from ['/dlabscratch1/veselovs/projects/llm-latent-language/babelnet_conf.yml']\n",
      "2024-06-17 18:43:04,011 [babelnet.api] INFO: BabelNet online RESTful API v1.2.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "from exp_tools import load_model\n",
    "\n",
    "model = load_model(\"/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf\")\n",
    "\n",
    "from translation_tools import prompts_from_df, get_bn_dataset\n",
    "\n",
    "de_df = get_bn_dataset(\"de\", \"de\")\n",
    "de_prompts = prompts_from_df(\"de\", \"de\", de_df)\n",
    "fr_df = get_bn_dataset(\"fr\", \"fr\")\n",
    "fr_prompts = prompts_from_df(\"fr\", \"fr\", fr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutsch: \"Ozean\" - Deutsch: \"Ozean\"\n",
      "Deutsch: \"Lied\" - Deutsch: \"Lied\"\n",
      "Deutsch: \"Norden\" - Deutsch: \"Norden\"\n",
      "Deutsch: \"Schule\" - Deutsch: \"Schule\"\n",
      "Deutsch: \"Osten\" - Deutsch: \"Osten\"\n",
      "Deutsch: \"Buch\" - Deutsch: \"\n"
     ]
    }
   ],
   "source": [
    "print(de_prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the mean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25f8d2b9914433f97b37de0d47e6301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 18:44:46,104 [nnsight] INFO: Dispatching `/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf`...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4723a570a6a4404ca48c91026a1ee436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 18:45:09,868 [nnsight] INFO: Dispatched `/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf`\n",
      "2024-06-17 18:45:09,870 [nnsight] INFO: Running `/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf`...\n",
      "2024-06-17 18:45:09,878 [nnsight] INFO: => SET(argument_0)\n",
      "2024-06-17 18:45:09,881 [nnsight] INFO: => DEL(argument_0)\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "2024-06-17 18:45:11,859 [nnsight] INFO: => SET(argument_1)\n",
      "2024-06-17 18:45:11,865 [nnsight] INFO: => SET(getitem_0)\n",
      "2024-06-17 18:45:11,991 [nnsight] INFO: => SET(getitem_1)\n",
      "2024-06-17 18:45:11,995 [nnsight] INFO: => SET(fetch_attr_0)\n",
      "2024-06-17 18:45:11,998 [nnsight] INFO: => SET(proxy_call_0)\n",
      "2024-06-17 18:45:12,001 [nnsight] INFO: => DEL(fetch_attr_0)\n",
      "2024-06-17 18:45:12,004 [nnsight] INFO: => DEL(getitem_1)\n",
      "2024-06-17 18:45:12,007 [nnsight] INFO: => DEL(getitem_0)\n",
      "2024-06-17 18:45:12,009 [nnsight] INFO: => DEL(argument_1)\n",
      "2024-06-17 18:45:12,018 [nnsight] INFO: => SET(argument_2)\n",
      "2024-06-17 18:45:12,022 [nnsight] INFO: => SET(getitem_2)\n",
      "2024-06-17 18:45:12,161 [nnsight] INFO: => SET(getitem_3)\n",
      "2024-06-17 18:45:12,165 [nnsight] INFO: => SET(fetch_attr_1)\n",
      "2024-06-17 18:45:12,168 [nnsight] INFO: => SET(proxy_call_1)\n",
      "2024-06-17 18:45:12,171 [nnsight] INFO: => DEL(fetch_attr_1)\n",
      "2024-06-17 18:45:12,175 [nnsight] INFO: => DEL(getitem_3)\n",
      "2024-06-17 18:45:12,177 [nnsight] INFO: => DEL(getitem_2)\n",
      "2024-06-17 18:45:12,179 [nnsight] INFO: => DEL(argument_2)\n",
      "2024-06-17 18:45:12,190 [nnsight] INFO: => SET(argument_3)\n",
      "2024-06-17 18:45:12,193 [nnsight] INFO: => SET(getitem_4)\n",
      "2024-06-17 18:45:12,326 [nnsight] INFO: => SET(getitem_5)\n",
      "2024-06-17 18:45:12,329 [nnsight] INFO: => SET(fetch_attr_2)\n",
      "2024-06-17 18:45:12,332 [nnsight] INFO: => SET(proxy_call_2)\n",
      "2024-06-17 18:45:12,335 [nnsight] INFO: => DEL(fetch_attr_2)\n",
      "2024-06-17 18:45:12,337 [nnsight] INFO: => DEL(getitem_5)\n",
      "2024-06-17 18:45:12,339 [nnsight] INFO: => DEL(getitem_4)\n",
      "2024-06-17 18:45:12,341 [nnsight] INFO: => DEL(argument_3)\n",
      "2024-06-17 18:45:12,351 [nnsight] INFO: => SET(argument_4)\n",
      "2024-06-17 18:45:12,354 [nnsight] INFO: => SET(getitem_6)\n",
      "2024-06-17 18:45:12,498 [nnsight] INFO: => SET(getitem_7)\n",
      "2024-06-17 18:45:12,501 [nnsight] INFO: => SET(fetch_attr_3)\n",
      "2024-06-17 18:45:12,507 [nnsight] INFO: => SET(proxy_call_3)\n",
      "2024-06-17 18:45:12,515 [nnsight] INFO: => DEL(fetch_attr_3)\n",
      "2024-06-17 18:45:12,517 [nnsight] INFO: => DEL(getitem_7)\n",
      "2024-06-17 18:45:12,521 [nnsight] INFO: => DEL(getitem_6)\n",
      "2024-06-17 18:45:12,524 [nnsight] INFO: => DEL(argument_4)\n",
      "2024-06-17 18:45:12,536 [nnsight] INFO: => SET(argument_5)\n",
      "2024-06-17 18:45:12,539 [nnsight] INFO: => SET(getitem_8)\n",
      "2024-06-17 18:45:12,679 [nnsight] INFO: => SET(getitem_9)\n",
      "2024-06-17 18:45:12,688 [nnsight] INFO: => SET(fetch_attr_4)\n",
      "2024-06-17 18:45:12,694 [nnsight] INFO: => SET(proxy_call_4)\n",
      "2024-06-17 18:45:12,697 [nnsight] INFO: => DEL(fetch_attr_4)\n",
      "2024-06-17 18:45:12,700 [nnsight] INFO: => DEL(getitem_9)\n",
      "2024-06-17 18:45:12,703 [nnsight] INFO: => DEL(getitem_8)\n",
      "2024-06-17 18:45:12,706 [nnsight] INFO: => DEL(argument_5)\n",
      "2024-06-17 18:45:12,715 [nnsight] INFO: => SET(argument_6)\n",
      "2024-06-17 18:45:12,718 [nnsight] INFO: => SET(getitem_10)\n",
      "2024-06-17 18:45:12,856 [nnsight] INFO: => SET(getitem_11)\n",
      "2024-06-17 18:45:12,859 [nnsight] INFO: => SET(fetch_attr_5)\n",
      "2024-06-17 18:45:12,863 [nnsight] INFO: => SET(proxy_call_5)\n",
      "2024-06-17 18:45:12,867 [nnsight] INFO: => DEL(fetch_attr_5)\n",
      "2024-06-17 18:45:12,870 [nnsight] INFO: => DEL(getitem_11)\n",
      "2024-06-17 18:45:12,873 [nnsight] INFO: => DEL(getitem_10)\n",
      "2024-06-17 18:45:12,876 [nnsight] INFO: => DEL(argument_6)\n",
      "2024-06-17 18:45:12,885 [nnsight] INFO: => SET(argument_7)\n",
      "2024-06-17 18:45:12,889 [nnsight] INFO: => SET(getitem_12)\n",
      "2024-06-17 18:45:13,028 [nnsight] INFO: => SET(getitem_13)\n",
      "2024-06-17 18:45:13,031 [nnsight] INFO: => SET(fetch_attr_6)\n",
      "2024-06-17 18:45:13,035 [nnsight] INFO: => SET(proxy_call_6)\n",
      "2024-06-17 18:45:13,038 [nnsight] INFO: => DEL(fetch_attr_6)\n",
      "2024-06-17 18:45:13,041 [nnsight] INFO: => DEL(getitem_13)\n",
      "2024-06-17 18:45:13,044 [nnsight] INFO: => DEL(getitem_12)\n",
      "2024-06-17 18:45:13,047 [nnsight] INFO: => DEL(argument_7)\n",
      "2024-06-17 18:45:13,060 [nnsight] INFO: => SET(argument_8)\n",
      "2024-06-17 18:45:13,064 [nnsight] INFO: => SET(getitem_14)\n",
      "2024-06-17 18:45:13,205 [nnsight] INFO: => SET(getitem_15)\n",
      "2024-06-17 18:45:13,209 [nnsight] INFO: => SET(fetch_attr_7)\n",
      "2024-06-17 18:45:13,212 [nnsight] INFO: => SET(proxy_call_7)\n",
      "2024-06-17 18:45:13,216 [nnsight] INFO: => DEL(fetch_attr_7)\n",
      "2024-06-17 18:45:13,219 [nnsight] INFO: => DEL(getitem_15)\n",
      "2024-06-17 18:45:13,222 [nnsight] INFO: => DEL(getitem_14)\n",
      "2024-06-17 18:45:13,225 [nnsight] INFO: => DEL(argument_8)\n",
      "2024-06-17 18:45:13,235 [nnsight] INFO: => SET(argument_9)\n",
      "2024-06-17 18:45:13,238 [nnsight] INFO: => SET(getitem_16)\n",
      "2024-06-17 18:45:13,377 [nnsight] INFO: => SET(getitem_17)\n",
      "2024-06-17 18:45:13,381 [nnsight] INFO: => SET(fetch_attr_8)\n",
      "2024-06-17 18:45:13,384 [nnsight] INFO: => SET(proxy_call_8)\n",
      "2024-06-17 18:45:13,387 [nnsight] INFO: => DEL(fetch_attr_8)\n",
      "2024-06-17 18:45:13,390 [nnsight] INFO: => DEL(getitem_17)\n",
      "2024-06-17 18:45:13,393 [nnsight] INFO: => DEL(getitem_16)\n",
      "2024-06-17 18:45:13,401 [nnsight] INFO: => DEL(argument_9)\n",
      "2024-06-17 18:45:13,413 [nnsight] INFO: => SET(argument_10)\n",
      "2024-06-17 18:45:13,418 [nnsight] INFO: => SET(getitem_18)\n",
      "2024-06-17 18:45:13,554 [nnsight] INFO: => SET(getitem_19)\n",
      "2024-06-17 18:45:13,557 [nnsight] INFO: => SET(fetch_attr_9)\n",
      "2024-06-17 18:45:13,561 [nnsight] INFO: => SET(proxy_call_9)\n",
      "2024-06-17 18:45:13,564 [nnsight] INFO: => DEL(fetch_attr_9)\n",
      "2024-06-17 18:45:13,567 [nnsight] INFO: => DEL(getitem_19)\n",
      "2024-06-17 18:45:13,570 [nnsight] INFO: => DEL(getitem_18)\n",
      "2024-06-17 18:45:13,572 [nnsight] INFO: => DEL(argument_10)\n",
      "2024-06-17 18:45:13,585 [nnsight] INFO: => SET(argument_11)\n",
      "2024-06-17 18:45:13,588 [nnsight] INFO: => SET(getitem_20)\n",
      "2024-06-17 18:45:13,730 [nnsight] INFO: => SET(getitem_21)\n",
      "2024-06-17 18:45:13,734 [nnsight] INFO: => SET(fetch_attr_10)\n",
      "2024-06-17 18:45:13,738 [nnsight] INFO: => SET(proxy_call_10)\n",
      "2024-06-17 18:45:13,741 [nnsight] INFO: => DEL(fetch_attr_10)\n",
      "2024-06-17 18:45:13,744 [nnsight] INFO: => DEL(getitem_21)\n",
      "2024-06-17 18:45:13,746 [nnsight] INFO: => DEL(getitem_20)\n",
      "2024-06-17 18:45:13,749 [nnsight] INFO: => DEL(argument_11)\n",
      "2024-06-17 18:45:13,762 [nnsight] INFO: => SET(argument_12)\n",
      "2024-06-17 18:45:13,766 [nnsight] INFO: => SET(getitem_22)\n",
      "2024-06-17 18:45:13,911 [nnsight] INFO: => SET(getitem_23)\n",
      "2024-06-17 18:45:13,914 [nnsight] INFO: => SET(fetch_attr_11)\n",
      "2024-06-17 18:45:13,918 [nnsight] INFO: => SET(proxy_call_11)\n",
      "2024-06-17 18:45:13,921 [nnsight] INFO: => DEL(fetch_attr_11)\n",
      "2024-06-17 18:45:13,924 [nnsight] INFO: => DEL(getitem_23)\n",
      "2024-06-17 18:45:13,927 [nnsight] INFO: => DEL(getitem_22)\n",
      "2024-06-17 18:45:13,930 [nnsight] INFO: => DEL(argument_12)\n",
      "2024-06-17 18:45:13,940 [nnsight] INFO: => SET(argument_13)\n",
      "2024-06-17 18:45:13,943 [nnsight] INFO: => SET(getitem_24)\n",
      "2024-06-17 18:45:14,081 [nnsight] INFO: => SET(getitem_25)\n",
      "2024-06-17 18:45:14,087 [nnsight] INFO: => SET(fetch_attr_12)\n",
      "2024-06-17 18:45:14,090 [nnsight] INFO: => SET(proxy_call_12)\n",
      "2024-06-17 18:45:14,093 [nnsight] INFO: => DEL(fetch_attr_12)\n",
      "2024-06-17 18:45:14,098 [nnsight] INFO: => DEL(getitem_25)\n",
      "2024-06-17 18:45:14,101 [nnsight] INFO: => DEL(getitem_24)\n",
      "2024-06-17 18:45:14,104 [nnsight] INFO: => DEL(argument_13)\n",
      "2024-06-17 18:45:14,114 [nnsight] INFO: => SET(argument_14)\n",
      "2024-06-17 18:45:14,118 [nnsight] INFO: => SET(getitem_26)\n",
      "2024-06-17 18:45:14,257 [nnsight] INFO: => SET(getitem_27)\n",
      "2024-06-17 18:45:14,261 [nnsight] INFO: => SET(fetch_attr_13)\n",
      "2024-06-17 18:45:14,265 [nnsight] INFO: => SET(proxy_call_13)\n",
      "2024-06-17 18:45:14,269 [nnsight] INFO: => DEL(fetch_attr_13)\n",
      "2024-06-17 18:45:14,272 [nnsight] INFO: => DEL(getitem_27)\n",
      "2024-06-17 18:45:14,275 [nnsight] INFO: => DEL(getitem_26)\n",
      "2024-06-17 18:45:14,278 [nnsight] INFO: => DEL(argument_14)\n",
      "2024-06-17 18:45:14,290 [nnsight] INFO: => SET(argument_15)\n",
      "2024-06-17 18:45:14,294 [nnsight] INFO: => SET(getitem_28)\n",
      "2024-06-17 18:45:14,437 [nnsight] INFO: => SET(getitem_29)\n",
      "2024-06-17 18:45:14,441 [nnsight] INFO: => SET(fetch_attr_14)\n",
      "2024-06-17 18:45:14,446 [nnsight] INFO: => SET(proxy_call_14)\n",
      "2024-06-17 18:45:14,449 [nnsight] INFO: => DEL(fetch_attr_14)\n",
      "2024-06-17 18:45:14,453 [nnsight] INFO: => DEL(getitem_29)\n",
      "2024-06-17 18:45:14,456 [nnsight] INFO: => DEL(getitem_28)\n",
      "2024-06-17 18:45:14,459 [nnsight] INFO: => DEL(argument_15)\n",
      "2024-06-17 18:45:14,472 [nnsight] INFO: => SET(argument_16)\n",
      "2024-06-17 18:45:14,475 [nnsight] INFO: => SET(getitem_30)\n",
      "2024-06-17 18:45:14,618 [nnsight] INFO: => SET(getitem_31)\n",
      "2024-06-17 18:45:14,622 [nnsight] INFO: => SET(fetch_attr_15)\n",
      "2024-06-17 18:45:14,626 [nnsight] INFO: => SET(proxy_call_15)\n",
      "2024-06-17 18:45:14,629 [nnsight] INFO: => DEL(fetch_attr_15)\n",
      "2024-06-17 18:45:14,632 [nnsight] INFO: => DEL(getitem_31)\n",
      "2024-06-17 18:45:14,635 [nnsight] INFO: => DEL(getitem_30)\n",
      "2024-06-17 18:45:14,637 [nnsight] INFO: => DEL(argument_16)\n",
      "2024-06-17 18:45:14,933 [nnsight] INFO: => SET(argument_17)\n",
      "2024-06-17 18:45:14,937 [nnsight] INFO: => SET(getitem_32)\n",
      "2024-06-17 18:45:15,019 [nnsight] INFO: => SET(getitem_33)\n",
      "2024-06-17 18:45:15,022 [nnsight] INFO: => SET(fetch_attr_16)\n",
      "2024-06-17 18:45:15,026 [nnsight] INFO: => SET(proxy_call_16)\n",
      "2024-06-17 18:45:15,029 [nnsight] INFO: => DEL(fetch_attr_16)\n",
      "2024-06-17 18:45:15,032 [nnsight] INFO: => DEL(getitem_33)\n",
      "2024-06-17 18:45:15,034 [nnsight] INFO: => DEL(getitem_32)\n",
      "2024-06-17 18:45:15,037 [nnsight] INFO: => DEL(argument_17)\n",
      "2024-06-17 18:45:15,046 [nnsight] INFO: => SET(argument_18)\n",
      "2024-06-17 18:45:15,050 [nnsight] INFO: => SET(getitem_34)\n",
      "2024-06-17 18:45:15,283 [nnsight] INFO: => SET(getitem_35)\n",
      "2024-06-17 18:45:15,285 [nnsight] INFO: => SET(fetch_attr_17)\n",
      "2024-06-17 18:45:15,289 [nnsight] INFO: => SET(proxy_call_17)\n",
      "2024-06-17 18:45:15,292 [nnsight] INFO: => DEL(fetch_attr_17)\n",
      "2024-06-17 18:45:15,294 [nnsight] INFO: => DEL(getitem_35)\n",
      "2024-06-17 18:45:15,297 [nnsight] INFO: => DEL(getitem_34)\n",
      "2024-06-17 18:45:15,300 [nnsight] INFO: => DEL(argument_18)\n",
      "2024-06-17 18:45:15,309 [nnsight] INFO: => SET(argument_19)\n",
      "2024-06-17 18:45:15,312 [nnsight] INFO: => SET(getitem_36)\n",
      "2024-06-17 18:45:15,562 [nnsight] INFO: => SET(getitem_37)\n",
      "2024-06-17 18:45:15,565 [nnsight] INFO: => SET(fetch_attr_18)\n",
      "2024-06-17 18:45:15,569 [nnsight] INFO: => SET(proxy_call_18)\n",
      "2024-06-17 18:45:15,573 [nnsight] INFO: => DEL(fetch_attr_18)\n",
      "2024-06-17 18:45:15,575 [nnsight] INFO: => DEL(getitem_37)\n",
      "2024-06-17 18:45:15,578 [nnsight] INFO: => DEL(getitem_36)\n",
      "2024-06-17 18:45:15,581 [nnsight] INFO: => DEL(argument_19)\n",
      "2024-06-17 18:45:15,593 [nnsight] INFO: => SET(argument_20)\n",
      "2024-06-17 18:45:15,596 [nnsight] INFO: => SET(getitem_38)\n",
      "2024-06-17 18:45:15,837 [nnsight] INFO: => SET(getitem_39)\n",
      "2024-06-17 18:45:15,841 [nnsight] INFO: => SET(fetch_attr_19)\n",
      "2024-06-17 18:45:15,845 [nnsight] INFO: => SET(proxy_call_19)\n",
      "2024-06-17 18:45:15,848 [nnsight] INFO: => DEL(fetch_attr_19)\n",
      "2024-06-17 18:45:15,851 [nnsight] INFO: => DEL(getitem_39)\n",
      "2024-06-17 18:45:15,854 [nnsight] INFO: => DEL(getitem_38)\n",
      "2024-06-17 18:45:15,857 [nnsight] INFO: => DEL(argument_20)\n",
      "2024-06-17 18:45:16,010 [nnsight] INFO: => SET(argument_21)\n",
      "2024-06-17 18:45:16,014 [nnsight] INFO: => SET(getitem_40)\n",
      "2024-06-17 18:45:16,087 [nnsight] INFO: => SET(getitem_41)\n",
      "2024-06-17 18:45:16,091 [nnsight] INFO: => SET(fetch_attr_20)\n",
      "2024-06-17 18:45:16,095 [nnsight] INFO: => SET(proxy_call_20)\n",
      "2024-06-17 18:45:16,098 [nnsight] INFO: => DEL(fetch_attr_20)\n",
      "2024-06-17 18:45:16,101 [nnsight] INFO: => DEL(getitem_41)\n",
      "2024-06-17 18:45:16,104 [nnsight] INFO: => DEL(getitem_40)\n",
      "2024-06-17 18:45:16,107 [nnsight] INFO: => DEL(argument_21)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU \u0001 has a total capacity of 11.92 GiB of which 960.00 KiB is free. Process 2796309 has 5.15 GiB memory in use. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.52 GiB is allocated by PyTorch, and 130.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexp_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_mean_activations\n\u001b[0;32m----> 2\u001b[0m de_means \u001b[38;5;241m=\u001b[39m \u001b[43mget_mean_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mde_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/projects/llm-latent-language/generalization/exp_tools.py:154\u001b[0m, in \u001b[0;36mget_mean_activations\u001b[0;34m(nn_model, prompts_str, batch_size)\u001b[0m\n\u001b[1;32m    152\u001b[0m acts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m--> 154\u001b[0m     acts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcollect_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    155\u001b[0m mean_activations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    156\u001b[0m num_layers \u001b[38;5;241m=\u001b[39m get_num_layers(nn_model)\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/projects/llm-latent-language/generalization/nnsight_utils.py:158\u001b[0m, in \u001b[0;36mcollect_activations\u001b[0;34m(nn_model, prompts, layers, get_activations, remote, idx)\u001b[0m\n\u001b[1;32m    156\u001b[0m     layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(get_num_layers(nn_model))\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Collect the hidden states of the last token of each prompt at each layer\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhiddens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtok_prompts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hiddens\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/nnsight/contexts/Runner.py:49\u001b[0m, in \u001b[0;36mRunner.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/nnsight/contexts/Tracer.py:69\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[0;32m---> 69\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mtracing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/nnsight/models/NNsightModel.py:245\u001b[0m, in \u001b[0;36mNNsight.interleave\u001b[0;34m(self, fn, intervention_graph, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m inputs, total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_inputs(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    243\u001b[0m intervention_handler \u001b[38;5;241m=\u001b[39m InterventionHandler(intervention_graph, total_batch_size)\n\u001b[0;32m--> 245\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mHookHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mintervention_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margument_node_names\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintervene\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintervention_handler\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintervene\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintervention_handler\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/nnsight/intervention.py:450\u001b[0m, in \u001b[0;36mHookHandler.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    447\u001b[0m     handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/nnsight/models/NNsightModel.py:255\u001b[0m, in \u001b[0;36mNNsight.interleave\u001b[0;34m(self, fn, intervention_graph, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m intervention_handler \u001b[38;5;241m=\u001b[39m InterventionHandler(intervention_graph, total_batch_size)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m HookHandler(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mlist\u001b[39m(intervention_graph\u001b[38;5;241m.\u001b[39margument_node_names\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m     ),\n\u001b[1;32m    254\u001b[0m ):\n\u001b[0;32m--> 255\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/nnsight/models/mixins/Generation.py:21\u001b[0m, in \u001b[0;36mGenerationMixin._execute\u001b[0;34m(self, prepared_inputs, generate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_generate(prepared_inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/nnsight/models/LanguageModel.py:291\u001b[0m, in \u001b[0;36mLanguageModel._execute_forward\u001b[0;34m(self, prepared_inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, prepared_inputs: Any, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    289\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepared_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1164\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1161\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:968\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    957\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    958\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    959\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    965\u001b[0m         cache_position,\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:726\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    725\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 726\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    728\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/veselovs/.conda/envs/llm-lang/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:87\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     85\u001b[0m input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     86\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 87\u001b[0m variance \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU \u0001 has a total capacity of 11.92 GiB of which 960.00 KiB is free. Process 2796309 has 5.15 GiB memory in use. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.52 GiB is allocated by PyTorch, and 130.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from exp_tools import get_mean_activations\n",
    "de_means = get_mean_activations(model, de_prompts, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"fr\", \"es\", \"de\", \"it\", \"zh\", \"ru\", \"ja\", \"en\"]\n",
    "# all_df = get_bn_dataset(\"en\", langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vectors = [neutral - de for de, neutral in zip(de_means, lang_means)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutsch: \"Auge\" - Deutsch: \"Auge\"\n",
      "Deutsch: \"Linie\" - Deutsch: \"Linie\"\n",
      "Deutsch: \"Person\" - Deutsch: \"Person\"\n",
      "Deutsch: \"Punkt\" - Deutsch: \"Punkt\"\n",
      "Deutsch: \"Tuch\" - Deutsch: \"Tuch\"\n",
      "Deutsch: \"Buch\n"
     ]
    }
   ],
   "source": [
    "from exp_tools import collect_activations\n",
    "buch_prompt = '\"'.join(de_prompts[0].split('\"')[:-2])\n",
    "print(buch_prompt)\n",
    "buch_latents = collect_activations(model, de_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_buch = [buch + steering for buch, steering in zip(buch_latents, steering_vectors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_prompt = \"\"\"Nuage: Un nuage est en mÃ©tÃ©orologie une masse visible constituÃ©e initialement d'une grande quantitÃ© de gouttelettes d'eau en suspension dans l'atmosphÃ¨re au-dessus de la surface d'une planÃ¨te.\n",
    "Stern: Unter einem Stern versteht man in der Astronomie einen massereichen, selbstleuchtenden HimmelskÃ¶rper aus sehr heiÃem Gas und Plasma, wie zum Beispiel die Sonne.\n",
    "Car: A car is a wheeled motor vehicle used for transportation. Most definitions of cars say that they run primarily on roads, seat one to eight people, have four tires, and mainly transport people rather than goods.\n",
    "Montagne: Une montagne est une forme topographique de relief positif, Ã  la surface de planÃ¨tes telluriques, et faisant partie d'un ensemble â une chaÃ®ne de montagnes â ou formant un relief isolÃ©.\n",
    "Tiger: The tiger (Panthera tigris) is the largest extant cat species and a member of the genus Panthera. It is most recognisable for its dark vertical stripes on orange-brown fur with a lighter underside.\n",
    "Wave: In physics, mathematics, and related fields, a wave is a propagating dynamic disturbance (change from equilibrium) of one or more quantities, sometimes as described by a wave equation.\n",
    "Wasser: Wasser ist insbesondere die chemische Verbindung H2O, bestehend aus den Elementen Sauerstoff und Wasserstoff.\n",
    "Maison: Une maison est un bÃ¢timent d'habitation, souvent de taille moyenne destinÃ© au logement d'une famille ou de plusieurs, sans Ãªtre considÃ©rÃ© comme un immeuble collectif.\n",
    "?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_prompt = \"\"\"Nuage: Un nuage est en mÃ©tÃ©orologie une masse visible constituÃ©e initialement d'une grande quantitÃ© de gouttelettes d'eau en suspension dans l'atmosphÃ¨re au-dessus de la surface d'une planÃ¨te.\n",
    "Ãtoile: Une Ã©toile est en astronomie un corps cÃ©leste massif et lumineux constituÃ© de gaz trÃ¨s chaud et de plasma, comme par exemple le Soleil.\n",
    "Voiture: Une voiture est un vÃ©hicule motorisÃ© Ã  roues utilisÃ© pour le transport. La plupart des dÃ©finitions des voitures disent qu'elles roulent principalement sur les routes, peuvent transporter de une Ã  huit personnes, ont quatre pneus, et transportent principalement des personnes plutÃ´t que des marchandises.\n",
    "Montagne: Une montagne est une forme topographique de relief positif, Ã  la surface de planÃ¨tes telluriques, et faisant partie d'un ensemble â une chaÃ®ne de montagnes â ou formant un relief isolÃ©.\n",
    "Tigre: Le tigre (Panthera tigris) est la plus grande espÃ¨ce de chat existante et un membre du genre Panthera. Il est reconnaissable par ses rayures verticales sombres sur un pelage orange-brun avec un dessous plus clair.\n",
    "Vague: En physique, en mathÃ©matiques et dans les domaines connexes, une vague est une perturbation dynamique propagative (changement d'Ã©quilibre) d'une ou de plusieurs quantitÃ©s, parfois dÃ©crite par une Ã©quation d'onde.\n",
    "Eau: L'eau est notamment la combinaison chimique H2O, constituÃ©e des Ã©lÃ©ments oxygÃ¨ne et hydrogÃ¨ne.\n",
    "Maison: Une maison est un bÃ¢timent d'habitation, souvent de taille moyenne destinÃ© au logement d'une famille ou de plusieurs, sans Ãªtre considÃ©rÃ© comme un immeuble collectif.\n",
    "?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22\u001b[39m\n\u001b[1;32m      3\u001b[0m max_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(description_prompt, max_new_tokens\u001b[38;5;241m=\u001b[39mmax_t):\n\u001b[1;32m      5\u001b[0m     get_layer_output(model, layer)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m neutral_buch[layer]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# probs = get_next_token_probs(model).save()\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from nnsight_utils import get_layer_output, get_next_token_probs\n",
    "layer = 22\n",
    "max_t = 20\n",
    "with model.generate(description_prompt, max_new_tokens=max_t):\n",
    "    get_layer_output(model, layer)[:, -1] = neutral_buch[layer]\n",
    "    # probs = get_next_token_probs(model).save()\n",
    "    gen = model.generator.output[0].cpu().save()\n",
    "print(model.tokenizer.decode(gen))\n",
    "with model.generate(description_prompt, max_new_tokens=max_t, do_sample=False):\n",
    "    get_layer_output(model, layer)[:, -1] = buch_latents[layer]\n",
    "    gen2 = model.generator.output[0].cpu().save()\n",
    "print()\n",
    "print(model.tokenizer.decode(gen2))\n",
    "with model.generate(description_prompt, max_new_tokens=max_t):\n",
    "    clean_gen = model.generator.output[0].cpu().save()\n",
    "print()\n",
    "print(model.tokenizer.decode(clean_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dlabscratch1/cdumas/llm-latent-language/generalization/../utils.py:490: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x50 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_topk_tokens(probs.cpu(), model.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steer using a random lang task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0074,  0.0091,  0.0113,  ..., -0.0054,  0.0243,  0.0221]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0018,  0.0263,  0.0040,  ...,  0.0092,  0.0114,  0.0438]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0171,  0.0144, -0.0501,  ...,  0.0216,  0.0551,  0.0649]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.0205,  0.0162,  0.0285,  ..., -0.0180,  0.0374,  0.0724]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0543,  0.0367, -0.0488,  ...,  0.0764,  0.1110,  0.0266]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0673,  0.0841, -0.0594,  ...,  0.1548,  0.1089,  0.0637]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0536,  0.0687,  0.0349,  ...,  0.3406,  0.0548,  0.0829]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0589, -0.0059,  0.0112,  ...,  0.2668, -0.0408,  0.0162]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0770, -0.0472,  0.1699,  ...,  0.2261, -0.1440,  0.1880]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.1116,  0.1022,  0.0139,  ...,  0.2405, -0.0396,  0.2170]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0732,  0.1594,  0.1627,  ...,  0.1284, -0.0787,  0.1302]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0493,  0.2421,  0.1609,  ...,  0.1868, -0.0568,  0.0535]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0503, -0.0441, -0.0984,  ...,  0.3477,  0.0699,  0.2026]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.1458,  0.1294, -0.1647,  ...,  0.2388,  0.1333,  0.2981]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0299,  0.0143, -0.4199,  ...,  0.0991,  0.2537,  0.3093]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.0458, -0.0864, -0.5195,  ..., -0.1367,  0.3384,  0.3757]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.2026, -0.2861, -0.9561,  ..., -0.1147,  0.8970,  0.3145]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.3337, -0.2822, -1.1562,  ..., -0.1982,  0.7656,  0.3110]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.3962, -0.1217, -1.1982,  ..., -0.4536,  0.8569,  0.0659]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.6479, -0.4224, -1.2568,  ..., -0.6621,  1.0996,  0.0404]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.4297, -0.2666, -1.0293,  ..., -0.5195,  1.1357,  0.0118]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.4263, -0.0178, -1.2510,  ..., -0.3101,  0.8140,  0.2661]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.5122,  0.6265, -1.4980,  ..., -0.3491,  0.6948,  0.1509]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.2983,  0.5752, -1.3916,  ..., -0.2478,  0.3101,  0.2010]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.2029,  0.7061, -1.3398,  ..., -0.4927, -0.1061,  0.4485]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.8076,  0.4778, -1.8672,  ..., -0.3025, -0.1554,  0.4822]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[ 0.2761,  0.5752, -2.1035,  ..., -0.3606, -0.1871,  0.5684]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.6475,  0.8013, -2.1836,  ..., -0.7061, -0.4878,  0.3350]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-0.7588,  1.5781, -2.9434,  ..., -0.9453,  0.0264,  0.9814]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-1.2783,  1.8291, -3.0898,  ..., -0.8193,  0.3076,  0.4009]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-1.4570,  2.0703, -3.0586,  ..., -0.7368, -0.8027,  1.0391]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[-1.4746,  1.4609, -4.1328,  ...,  1.8193, -0.0166,  1.4326]],\n",
       "        dtype=torch.float16)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buch_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "dataset = {\n",
    "    \"A\": [],\n",
    "    \"B\": [],\n",
    "}\n",
    "num_rep = 5\n",
    "for _, row in all_df.iterrows():\n",
    "    dataset[\"A\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"A: cat, B: Katze\\nA:DOG^FR, B: DOG^ZH\\nA:CLOUD^RU\\nB:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
