{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "\n",
    "# Fix logger bug\n",
    "import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "\n",
    "th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model = \"croissantllm/CroissantLLMBase\"\n",
    "model_path = None\n",
    "check_translation_performance = False\n",
    "batch_size = 64\n",
    "thinking_langs = [\"en\", \"fr\"]\n",
    "langs = [\"en\", \"fr\", \"de\", \"ru\", \"zh\"]\n",
    "method = \"logit_lens\"\n",
    "trust_remote_code = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"llama\" not in method:\n",
    "    method = method + \"_llama\"\n",
    "langs = np.array(langs)\n",
    "out_langs = {lang: np.array([l for l in langs if l != lang]) for lang in langs}\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = LanguageModel(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=th.float16,\n",
    "    trust_remote_code=trust_remote_code,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_translation_performance:\n",
    "    from exp_tools import get_translations, translation_prompts, logit_lens_llama\n",
    "\n",
    "    accuracies = np.ones((len(langs), len(langs)))\n",
    "    translation_accuracies = {\n",
    "        (lang, l): 1 for lang, l in itertools.product(langs, langs)\n",
    "    }\n",
    "    probs = np.ones((len(langs), len(langs)))\n",
    "    df = get_translations(langs)\n",
    "    for i, input_lang in enumerate(langs):\n",
    "        for j, output_lang in enumerate(langs):\n",
    "            if input_lang == output_lang:\n",
    "                continue\n",
    "            prompts = translation_prompts(\n",
    "                df, nn_model.tokenizer, input_lang, output_lang, output_lang\n",
    "            )\n",
    "            success = 0\n",
    "            str_prompts = [p.prompt for p in prompts]\n",
    "            with th.no_grad():\n",
    "                with nn_model.generate(\n",
    "                    str_prompts,\n",
    "                    max_new_tokens=1,\n",
    "                    # pad_token_id=nn_model.tokenizer.eos_token_id,\n",
    "                    do_sample=False,\n",
    "                ) as tracer:\n",
    "                    output = nn_model.generator.output.save()\n",
    "            for ip, p in enumerate(prompts):\n",
    "                if output[ip][-1].item() in p.target_tokens:\n",
    "                    success += 1\n",
    "            accuracies[i, j] = success / len(prompts)\n",
    "            translation_accuracies[(input_lang, output_lang)] = accuracies[i, j]\n",
    "            llens = logit_lens_llama(nn_model, str_prompts)\n",
    "            cum_probs = 0\n",
    "            for ip, p in enumerate(prompts):\n",
    "                cum_probs[i, j] += llens[ip, -1, p.target_tokens].sum()\n",
    "            probs[i, j] = cum_probs / len(prompts)\n",
    "            print(\n",
    "                f\"Accuracy {input_lang} -> {output_lang}:\\nAcc: {accuracies[i, j]}\\nProb: {probs[i, j]}\"\n",
    "            )\n",
    "\n",
    "    sns.heatmap(\n",
    "        accuracies, annot=True, cmap=\"YlGnBu\", xticklabels=langs, yticklabels=langs\n",
    "    )\n",
    "    plt.title(\"Translation Accuracies\")\n",
    "    plt.xlabel(\"Output Language\")\n",
    "    plt.ylabel(\"Input Language\")\n",
    "    plt.show()\n",
    "    sns.heatmap(probs, annot=True, cmap=\"YlGnBu\", xticklabels=langs, yticklabels=langs)\n",
    "    plt.title(\"Translation Mean Probabilities\")\n",
    "    plt.xlabel(\"Output Language\")\n",
    "    plt.ylabel(\"Input Language\")\n",
    "    plt.show()\n",
    "    mean_accuracies = accuracies.mean(axis=1)\n",
    "    sorted_indices = np.argsort(mean_accuracies)[::-1]\n",
    "    langs = langs[sorted_indices]\n",
    "    for lang in langs:\n",
    "        out_langs[lang] = sorted(\n",
    "            out_langs[lang],\n",
    "            key=lambda l: translation_accuracies[(lang, l)],\n",
    "            reverse=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit Lens plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import run_prompts\n",
    "from translation_tools import translation_prompts\n",
    "\n",
    "from translation_tools import get_bn_dataset as get_translations\n",
    "\n",
    "# from translation_tools import get_gpt4_dataset as get_translations\n",
    "from utils import plot_ci\n",
    "\n",
    "\n",
    "def translation_plot(\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    latent_langs,\n",
    "    batch_size=batch_size,\n",
    "    method=method,\n",
    "    num_words=None,\n",
    "    ax=None,\n",
    "    time_=None,\n",
    "):\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    global df, prompts, target_probs, latent_probs\n",
    "    if isinstance(latent_langs, str):\n",
    "        latent_langs = [latent_langs]\n",
    "    if time_ is None:\n",
    "        time_ = str(int(time()))\n",
    "    else:\n",
    "        time_ = \"/\" + str(time_)\n",
    "    df = get_translations(input_lang, [target_lang] + latent_langs, num_words=num_words)\n",
    "    prompts = translation_prompts(\n",
    "        df, nn_model.tokenizer, input_lang, target_lang, latent_langs\n",
    "    )\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, prompts, batch_size=batch_size, method=method\n",
    "    )\n",
    "    json_dic = {target_lang: target_probs.tolist()}\n",
    "    for lang, probs in latent_probs.items():\n",
    "        json_dic[lang] = probs.tolist()\n",
    "    path = Path(\"results\") / model_name / \"translation\"\n",
    "    json_file = path / (\n",
    "        \"_\".join([input_lang, target_lang, *latent_langs, time_]) + \".json\"\n",
    "    )\n",
    "    json_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    colors = sns.color_palette(\"tab10\", len(latent_langs) + 1)\n",
    "    plot_ci(ax, target_probs, label=target_lang, color=colors[0])\n",
    "    colors = {lang: color for lang, color in zip(latent_langs, colors[1:])}\n",
    "    for latent_lang, probs in latent_probs.items():\n",
    "        plot_ci(ax, probs, label=latent_lang, color=colors[latent_lang])\n",
    "    ax.legend()\n",
    "    ax.set_title(\n",
    "        f\"{method} on {model_name}: Translation from {input_lang} to {target_lang}\"\n",
    "    )\n",
    "    # Save the plot\n",
    "    plot_file = path / (\n",
    "        \"_\".join([input_lang, target_lang, *latent_langs, time_]) + \".png\"\n",
    "    )\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ = int(time())\n",
    "print(f\"Experiment time id: {time_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in_lang in langs:\n",
    "    for out_lang in out_langs[in_lang]:\n",
    "        translation_plot(\n",
    "            in_lang, out_lang, [t for t in thinking_langs if t != out_lang], time_=time_\n",
    "        )\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
