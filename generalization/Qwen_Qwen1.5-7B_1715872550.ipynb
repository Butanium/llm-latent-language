{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964bcdb2",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [9]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a282f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:15:52.115943Z",
     "iopub.status.busy": "2024-05-16T15:15:52.115255Z",
     "iopub.status.idle": "2024-05-16T15:15:52.136943Z",
     "shell.execute_reply": "2024-05-16T15:15:52.136442Z"
    },
    "papermill": {
     "duration": 0.028335,
     "end_time": "2024-05-16T15:15:52.137993",
     "exception": false,
     "start_time": "2024-05-16T15:15:52.109658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ed52f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:15:52.146873Z",
     "iopub.status.busy": "2024-05-16T15:15:52.146413Z",
     "iopub.status.idle": "2024-05-16T15:16:01.903767Z",
     "shell.execute_reply": "2024-05-16T15:16:01.903159Z"
    },
    "papermill": {
     "duration": 9.762639,
     "end_time": "2024-05-16T15:16:01.904822",
     "exception": false,
     "start_time": "2024-05-16T15:15:52.142183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 15:16:00,317 [babelnet.conf] INFO: Loaded configuration from ['/dlabscratch1/dlabscratch1/cdumas/babelnet_conf.yml']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 15:16:00,321 [babelnet.api] INFO: BabelNet online RESTful API v1.2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f072dadf290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "\n",
    "# Fix logger bug\n",
    "import babelnet\n",
    "from nnsight import logger\n",
    "\n",
    "logger.disabled = True\n",
    "\n",
    "th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a608f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:16:01.914121Z",
     "iopub.status.busy": "2024-05-16T15:16:01.913830Z",
     "iopub.status.idle": "2024-05-16T15:16:01.950383Z",
     "shell.execute_reply": "2024-05-16T15:16:01.949830Z"
    },
    "papermill": {
     "duration": 0.042127,
     "end_time": "2024-05-16T15:16:01.951348",
     "exception": false,
     "start_time": "2024-05-16T15:16:01.909221",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model = \"croissantllm/CroissantLLMBase\"\n",
    "model_path = None\n",
    "check_translation_performance = False\n",
    "batch_size = 64\n",
    "thinking_langs = [\"en\", \"fr\"]\n",
    "langs = [\"en\", \"fr\", \"de\", \"ru\", \"zh\"]\n",
    "method = \"logit_lens\"\n",
    "trust_remote_code = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac6cc40a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:16:01.961465Z",
     "iopub.status.busy": "2024-05-16T15:16:01.961252Z",
     "iopub.status.idle": "2024-05-16T15:16:01.997486Z",
     "shell.execute_reply": "2024-05-16T15:16:01.996960Z"
    },
    "papermill": {
     "duration": 0.042112,
     "end_time": "2024-05-16T15:16:01.998389",
     "exception": false,
     "start_time": "2024-05-16T15:16:01.956277",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "check_translation_performance = False\n",
    "langs = [\"fr\", \"de\", \"ru\", \"en\", \"zh\"]\n",
    "batch_size = 16\n",
    "model = \"Qwen/Qwen1.5-7B\"\n",
    "thinking_langs = [\"en\", \"zh\"]\n",
    "model_path = None\n",
    "trust_remote_code = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfd94d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:16:02.007181Z",
     "iopub.status.busy": "2024-05-16T15:16:02.006833Z",
     "iopub.status.idle": "2024-05-16T15:16:02.849390Z",
     "shell.execute_reply": "2024-05-16T15:16:02.848224Z"
    },
    "papermill": {
     "duration": 0.848444,
     "end_time": "2024-05-16T15:16:02.850698",
     "exception": false,
     "start_time": "2024-05-16T15:16:02.002254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "if \"llama\" not in method:\n",
    "    method = method + \"_llama\"\n",
    "    model_path = model\n",
    "langs = np.array(langs)\n",
    "out_langs = {lang: np.array([l for l in langs if l != lang]) for lang in langs}\n",
    "nn_model = LanguageModel(\n",
    "    model_path,\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=th.float16,\n",
    "    trust_remote_code=trust_remote_code,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb7343",
   "metadata": {
    "papermill": {
     "duration": 0.015891,
     "end_time": "2024-05-16T15:16:02.891400",
     "exception": false,
     "start_time": "2024-05-16T15:16:02.875509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Translation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55af2b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:16:02.913161Z",
     "iopub.status.busy": "2024-05-16T15:16:02.912807Z",
     "iopub.status.idle": "2024-05-16T15:16:02.961148Z",
     "shell.execute_reply": "2024-05-16T15:16:02.960478Z"
    },
    "papermill": {
     "duration": 0.058937,
     "end_time": "2024-05-16T15:16:02.962748",
     "exception": false,
     "start_time": "2024-05-16T15:16:02.903811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if check_translation_performance:\n",
    "    from exp_tools import get_translations, translation_prompts, logit_lens_llama\n",
    "\n",
    "    accuracies = np.ones((len(langs), len(langs)))\n",
    "    translation_accuracies = {\n",
    "        (lang, l): 1 for lang, l in itertools.product(langs, langs)\n",
    "    }\n",
    "    probs = np.ones((len(langs), len(langs)))\n",
    "    df = get_translations(langs)\n",
    "    for i, input_lang in enumerate(langs):\n",
    "        for j, output_lang in enumerate(langs):\n",
    "            if input_lang == output_lang:\n",
    "                continue\n",
    "            prompts = translation_prompts(\n",
    "                df, nn_model.tokenizer, input_lang, output_lang, output_lang\n",
    "            )\n",
    "            success = 0\n",
    "            str_prompts = [p.prompt for p in prompts]\n",
    "            with th.no_grad():\n",
    "                with nn_model.generate(\n",
    "                    str_prompts,\n",
    "                    max_new_tokens=1,\n",
    "                    # pad_token_id=nn_model.tokenizer.eos_token_id,\n",
    "                    do_sample=False,\n",
    "                ) as tracer:\n",
    "                    output = nn_model.generator.output.save()\n",
    "            for ip, p in enumerate(prompts):\n",
    "                if output[ip][-1].item() in p.target_tokens:\n",
    "                    success += 1\n",
    "            accuracies[i, j] = success / len(prompts)\n",
    "            translation_accuracies[(input_lang, output_lang)] = accuracies[i, j]\n",
    "            llens = logit_lens_llama(nn_model, str_prompts)\n",
    "            cum_probs = 0\n",
    "            for ip, p in enumerate(prompts):\n",
    "                cum_probs[i, j] += llens[ip, -1, p.target_tokens].sum()\n",
    "            probs[i, j] = cum_probs / len(prompts)\n",
    "            print(\n",
    "                f\"Accuracy {input_lang} -> {output_lang}:\\nAcc: {accuracies[i, j]}\\nProb: {probs[i, j]}\"\n",
    "            )\n",
    "\n",
    "    sns.heatmap(\n",
    "        accuracies, annot=True, cmap=\"YlGnBu\", xticklabels=langs, yticklabels=langs\n",
    "    )\n",
    "    plt.title(\"Translation Accuracies\")\n",
    "    plt.xlabel(\"Output Language\")\n",
    "    plt.ylabel(\"Input Language\")\n",
    "    plt.show()\n",
    "    sns.heatmap(probs, annot=True, cmap=\"YlGnBu\", xticklabels=langs, yticklabels=langs)\n",
    "    plt.title(\"Translation Mean Probabilities\")\n",
    "    plt.xlabel(\"Output Language\")\n",
    "    plt.ylabel(\"Input Language\")\n",
    "    plt.show()\n",
    "    mean_accuracies = accuracies.mean(axis=1)\n",
    "    sorted_indices = np.argsort(mean_accuracies)[::-1]\n",
    "    langs = langs[sorted_indices]\n",
    "    for lang in langs:\n",
    "        out_langs[lang] = sorted(\n",
    "            out_langs[lang],\n",
    "            key=lambda l: translation_accuracies[(lang, l)],\n",
    "            reverse=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c3c96",
   "metadata": {
    "papermill": {
     "duration": 0.003828,
     "end_time": "2024-05-16T15:16:02.971486",
     "exception": false,
     "start_time": "2024-05-16T15:16:02.967658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Logit Lens plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13f8217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:16:02.980404Z",
     "iopub.status.busy": "2024-05-16T15:16:02.980246Z",
     "iopub.status.idle": "2024-05-16T15:16:05.553972Z",
     "shell.execute_reply": "2024-05-16T15:16:05.553192Z"
    },
    "papermill": {
     "duration": 2.579906,
     "end_time": "2024-05-16T15:16:05.555524",
     "exception": false,
     "start_time": "2024-05-16T15:16:02.975618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 15:16:03,184 [datasets] INFO: PyTorch version 2.2.2 available.\n"
     ]
    }
   ],
   "source": [
    "from exp_tools import run_prompts\n",
    "from translation_tools import translation_prompts\n",
    "\n",
    "from translation_tools import get_bn_dataset as get_translations\n",
    "\n",
    "# from translation_tools import get_gpt4_dataset as get_translations\n",
    "from utils import plot_ci\n",
    "\n",
    "\n",
    "def translation_plot(\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    latent_langs,\n",
    "    batch_size=batch_size,\n",
    "    method=method,\n",
    "    num_words=None,\n",
    "    ax=None,\n",
    "    time_=None,\n",
    "):\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    global df, prompts, target_probs, latent_probs\n",
    "    if isinstance(latent_langs, str):\n",
    "        latent_langs = [latent_langs]\n",
    "    if time_ is None:\n",
    "        time_ = str(int(time()))\n",
    "    else:\n",
    "        time_ = \"/\" + str(time_)\n",
    "    df = get_translations(input_lang, [target_lang] + latent_langs, num_words=num_words)\n",
    "    prompts = translation_prompts(\n",
    "        df, nn_model.tokenizer, input_lang, target_lang, latent_langs\n",
    "    )\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, prompts, batch_size=batch_size, method=method\n",
    "    )\n",
    "    json_dic = {target_lang: target_probs.tolist()}\n",
    "    for lang, probs in latent_probs.items():\n",
    "        json_dic[lang] = probs.tolist()\n",
    "    path = Path(\"results\") / model_name / \"translation\"\n",
    "    json_file = path / (\n",
    "        \"_\".join([input_lang, target_lang, *latent_langs, time_]) + \".json\"\n",
    "    )\n",
    "    json_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    colors = sns.color_palette(\"tab10\", len(latent_langs) + 1)\n",
    "    plot_ci(ax, target_probs, label=target_lang, color=colors[0])\n",
    "    colors = {lang: color for lang, color in zip(latent_langs, colors[1:])}\n",
    "    for latent_lang, probs in latent_probs.items():\n",
    "        plot_ci(ax, probs, label=latent_lang, color=colors[latent_lang])\n",
    "    ax.legend()\n",
    "    ax.set_title(\n",
    "        f\"{method} on {model_name}: Translation from {input_lang} to {target_lang}\"\n",
    "    )\n",
    "    # Save the plot\n",
    "    plot_file = path / (\n",
    "        \"_\".join([input_lang, target_lang, *latent_langs, time_]) + \".png\"\n",
    "    )\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4db38",
   "metadata": {
    "papermill": {
     "duration": 0.00489,
     "end_time": "2024-05-16T15:16:05.565673",
     "exception": false,
     "start_time": "2024-05-16T15:16:05.560783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Thinking language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f2d8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:16:05.576428Z",
     "iopub.status.busy": "2024-05-16T15:16:05.576097Z",
     "iopub.status.idle": "2024-05-16T15:16:05.635936Z",
     "shell.execute_reply": "2024-05-16T15:16:05.635253Z"
    },
    "papermill": {
     "duration": 0.066697,
     "end_time": "2024-05-16T15:16:05.637005",
     "exception": false,
     "start_time": "2024-05-16T15:16:05.570308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment time id: 1715872565\n"
     ]
    }
   ],
   "source": [
    "time_ = int(time())\n",
    "print(f\"Experiment time id: {time_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f29da2",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0befd320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T15:16:05.647924Z",
     "iopub.status.busy": "2024-05-16T15:16:05.647391Z",
     "iopub.status.idle": "2024-05-16T15:16:08.174565Z",
     "shell.execute_reply": "2024-05-16T15:16:08.173714Z"
    },
    "papermill": {
     "duration": 2.533447,
     "end_time": "2024-05-16T15:16:08.175401",
     "exception": true,
     "start_time": "2024-05-16T15:16:05.641954",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097b94fdd8064610967245127d4232c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 translations\n",
      "Gewölk\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 16: 'b6lk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m in_lang \u001b[38;5;129;01min\u001b[39;00m langs:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m out_lang \u001b[38;5;129;01min\u001b[39;00m out_langs[in_lang]:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mtranslation_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43min_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mthinking_langs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_lang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36mtranslation_plot\u001b[0;34m(input_lang, target_lang, latent_langs, batch_size, method, num_words, ax, time_)\u001b[0m\n\u001b[1;32m     27\u001b[0m     time_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(time_)\n\u001b[1;32m     28\u001b[0m df \u001b[38;5;241m=\u001b[39m get_translations(input_lang, [target_lang] \u001b[38;5;241m+\u001b[39m latent_langs, num_words\u001b[38;5;241m=\u001b[39mnum_words)\n\u001b[0;32m---> 29\u001b[0m prompts \u001b[38;5;241m=\u001b[39m \u001b[43mtranslation_prompts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_langs\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m target_probs, latent_probs \u001b[38;5;241m=\u001b[39m run_prompts(\n\u001b[1;32m     33\u001b[0m     nn_model, prompts, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m json_dic \u001b[38;5;241m=\u001b[39m {target_lang: target_probs\u001b[38;5;241m.\u001b[39mtolist()}\n",
      "File \u001b[0;32m~/llm-latent-language/generalization/translation_tools.py:300\u001b[0m, in \u001b[0;36mtranslation_prompts\u001b[0;34m(df, tokenizer, input_lang, target_lang, latent_langs, n, only_best)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m only_best \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target_words, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    299\u001b[0m     target_words \u001b[38;5;241m=\u001b[39m target_words[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 300\u001b[0m target_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok_vocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m latent_tokens \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    302\u001b[0m latent_words \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/llm-latent-language/generalization/../generalization/exp_tools.py:70\u001b[0m, in \u001b[0;36mprocess_tokens\u001b[0;34m(words, tok_vocab)\u001b[0m\n\u001b[1;32m     68\u001b[0m final_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[0;32m---> 70\u001b[0m     with_prefixes \u001b[38;5;241m=\u001b[39m token_prefixes(word) \u001b[38;5;241m+\u001b[39m \u001b[43municode_prefixes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     with_spaces \u001b[38;5;241m=\u001b[39m add_spaces(with_prefixes)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m with_spaces:\n",
      "File \u001b[0;32m~/llm-latent-language/generalization/../generalization/exp_tools.py:50\u001b[0m, in \u001b[0;36municode_prefixes\u001b[0;34m(tok_str)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# We need to convert back to latin1 to get the character\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     chr_bytes \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchr_bytes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tok_str)\n",
      "File \u001b[0;32m~/llm-latent-language/generalization/../generalization/exp_tools.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# We need to convert back to latin1 to get the character\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     chr_bytes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m chr_bytes]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tok_str)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 16: 'b6lk'"
     ]
    }
   ],
   "source": [
    "for in_lang in langs:\n",
    "    for out_lang in out_langs[in_lang]:\n",
    "        translation_plot(\n",
    "            in_lang, out_lang, [t for t in thinking_langs if t != out_lang], time_=time_\n",
    "        )\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.29973,
   "end_time": "2024-05-16T15:16:09.597999",
   "environment_variables": {},
   "exception": true,
   "input_path": "/dlabscratch1/dlabscratch1/cdumas/llm-latent-language/generalization/translation_llama.ipynb",
   "output_path": "/dlabscratch1/dlabscratch1/cdumas/llm-latent-language/generalization/results/Qwen_Qwen1.5-7B_1715872550.ipynb",
   "parameters": {
    "batch_size": 16,
    "check_translation_performance": false,
    "langs": [
     "fr",
     "de",
     "ru",
     "en",
     "zh"
    ],
    "model": "Qwen/Qwen1.5-7B",
    "model_path": null,
    "thinking_langs": [
     "en",
     "zh"
    ],
    "trust_remote_code": false
   },
   "start_time": "2024-05-16T15:15:50.298269",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03f9a236e9484f0292f1405c9d487823": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "097b94fdd8064610967245127d4232c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8b8b5fcd480e4d159749275c18b38d35",
        "IPY_MODEL_0ff725bb0ebb4d28b9ae7c680663caa5",
        "IPY_MODEL_98b32d7d31cb47da8b07980babcb2e32"
       ],
       "layout": "IPY_MODEL_5b714d6661314350957be762723e22cd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0ff725bb0ebb4d28b9ae7c680663caa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d488ad0903e044e580a5c945514f8fb9",
       "max": 118,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03f9a236e9484f0292f1405c9d487823",
       "tabbable": null,
       "tooltip": null,
       "value": 118
      }
     },
     "5b32032a6ec546048eeb4392d25bfa2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5b714d6661314350957be762723e22cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7807b9def82b4f6a8f9b28b74214bbda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b8b5fcd480e4d159749275c18b38d35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7807b9def82b4f6a8f9b28b74214bbda",
       "placeholder": "​",
       "style": "IPY_MODEL_5b32032a6ec546048eeb4392d25bfa2d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "8eecebd5614a4b1b9695fbbd672785b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98b32d7d31cb47da8b07980babcb2e32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8eecebd5614a4b1b9695fbbd672785b1",
       "placeholder": "​",
       "style": "IPY_MODEL_e973b9a2837745578f3e0ab457141054",
       "tabbable": null,
       "tooltip": null,
       "value": " 118/118 [00:01&lt;00:00, 68.35it/s]"
      }
     },
     "d488ad0903e044e580a5c945514f8fb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e973b9a2837745578f3e0ab457141054": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
